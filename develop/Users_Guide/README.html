

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>26. README - Configuration File Overview &mdash; MET develop documentation</title>
  

  
  
  
  
    <link rel="canonical" href="https://dtcenter.github.io/MET/latest/Users_Guide/README.html"/>
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  

  
    <link rel="stylesheet" href="../_static/theme_override.css" type="text/css" />
  

  
        <link rel="index" title="Index"
              href="../genindex.html"/>
        <link rel="search" title="Search" href="../search.html"/>
    <link rel="top" title="MET develop documentation" href="../index.html"/>
        <link rel="up" title="User’s Guide" href="index.html"/>
        <link rel="next" title="27. README_TC Configuration File Overview" href="README_TC.html"/>
        <link rel="prev" title="25. Plotting and Graphics Support" href="plotting.html"/> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> MET
          

          
            
            <img src="../_static/met_logo_2019_09.png" class="logo" />
          
          </a>

          
            
            
              <div class="version">
                
                  <div class="version-dropdown">
                    <select class="version-list" id="version-list">
                      <option value=''>develop</option>
                      
                        
                          <option value="../latest">latest</option>
                        
                      
                        
                      
                    </select>
                  </div>
                
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Model Evaluation Tools</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">User’s Guide</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="overview.html">1. Overview of MET</a></li>
<li class="toctree-l2"><a class="reference internal" href="installation.html">2. Software Installation/Getting Started</a></li>
<li class="toctree-l2"><a class="reference internal" href="data_io.html">3. MET Data I/O</a></li>
<li class="toctree-l2"><a class="reference internal" href="reformat_point.html">4. Re-Formatting of Point Observations</a></li>
<li class="toctree-l2"><a class="reference internal" href="reformat_grid.html">5. Re-Formatting of Gridded Fields</a></li>
<li class="toctree-l2"><a class="reference internal" href="masking.html">6. Regional Verification using Spatial Masking</a></li>
<li class="toctree-l2"><a class="reference internal" href="point-stat.html">7. Point-Stat Tool</a></li>
<li class="toctree-l2"><a class="reference internal" href="grid-stat.html">8. Grid-Stat Tool</a></li>
<li class="toctree-l2"><a class="reference internal" href="ensemble-stat.html">9. Ensemble-Stat Tool</a></li>
<li class="toctree-l2"><a class="reference internal" href="wavelet-stat.html">10. Wavelet-Stat Tool</a></li>
<li class="toctree-l2"><a class="reference internal" href="gsi-tools.html">11. GSI Tools</a></li>
<li class="toctree-l2"><a class="reference internal" href="stat-analysis.html">12. Stat-Analysis Tool</a></li>
<li class="toctree-l2"><a class="reference internal" href="series-analysis.html">13. Series-Analysis Tool</a></li>
<li class="toctree-l2"><a class="reference internal" href="grid-diag.html">14. Grid-Diag Tool</a></li>
<li class="toctree-l2"><a class="reference internal" href="mode.html">15. MODE Tool</a></li>
<li class="toctree-l2"><a class="reference internal" href="mode-analysis.html">16. MODE-Analysis Tool</a></li>
<li class="toctree-l2"><a class="reference internal" href="mode-td.html">17. MODE Time Domain Tool</a></li>
<li class="toctree-l2"><a class="reference internal" href="met-tc_overview.html">18. MET-TC Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="tc-dland.html">19. TC-Dland Tool</a></li>
<li class="toctree-l2"><a class="reference internal" href="tc-pairs.html">20. TC-Pairs Tool</a></li>
<li class="toctree-l2"><a class="reference internal" href="tc-stat.html">21. TC-Stat Tool</a></li>
<li class="toctree-l2"><a class="reference internal" href="tc-gen.html">22. TC-Gen Tool</a></li>
<li class="toctree-l2"><a class="reference internal" href="tc-rmw.html">23. TC-RMW Tool</a></li>
<li class="toctree-l2"><a class="reference internal" href="rmw-analysis.html">24. RMW-Analysis Tool</a></li>
<li class="toctree-l2"><a class="reference internal" href="plotting.html">25. Plotting and Graphics Support</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">26. README - Configuration File Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#configuration-settings-used-by-the-met-tools">26.1. Configuration settings used by the MET tools</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#settings-common-to-multiple-tools">26.1.1. Settings common to multiple tools</a></li>
<li class="toctree-l4"><a class="reference internal" href="#settings-specific-to-individual-tools">26.1.2. Settings specific to individual tools</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="README_TC.html">27. README_TC Configuration File Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="refs.html">28. References</a></li>
<li class="toctree-l2"><a class="reference internal" href="appendixA.html">29. Appendix A FAQs &amp; How do I … ?</a></li>
<li class="toctree-l2"><a class="reference internal" href="appendixB.html">30. Appendix B Map Projections, Grids, and Polylines</a></li>
<li class="toctree-l2"><a class="reference internal" href="appendixC.html">31. Appendix C Verification Measures</a></li>
<li class="toctree-l2"><a class="reference internal" href="appendixD.html">32. Appendix D Confidence Intervals</a></li>
<li class="toctree-l2"><a class="reference internal" href="appendixE.html">33. Appendix E WWMCA Tools</a></li>
<li class="toctree-l2"><a class="reference internal" href="appendixF.html">34. Appendix F Python Embedding</a></li>
<li class="toctree-l2"><a class="reference internal" href="appendixG.html">35. Appendix G Vectors and Vector Statistics</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#indices-and-tables">Indices and tables</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../Contributors_Guide/index.html">Contributor’s Guide</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MET</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="index.html">User’s Guide</a> &raquo;</li>
        
      <li><span class="section-number">26. </span>README - Configuration File Overview</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/Users_Guide/README.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="readme-configuration-file-overview">
<span id="readme"></span><h1><span class="section-number">26. </span>README - Configuration File Overview<a class="headerlink" href="#readme-configuration-file-overview" title="Permalink to this headline">¶</a></h1>
<p>The configuration files that control many of the MET tools contain formatted
ASCII text. This format has been updated for MET version develop and
continues to be used in subsequent releases.</p>
<p>Settings common to multiple tools are described in the top part of this README
file and settings specific to individual tools are described beneath the common
settings. Please refer to the MET User’s Guide in the “doc” directory for more
details about the settings if necessary.</p>
<p>A configuration file entry is an entry name, followed by an equal sign (=),
followed by an entry value, and is terminated by a semicolon (;). The
configuration file itself is one large dictionary consisting of entries, some of
which are dictionaries themselves.</p>
<p>The configuration file language supports the following data types:</p>
<ul class="simple">
<li><p>Dictionary:</p>
<ul>
<li><p>Grouping of one or more entries enclosed by curly braces {}.</p></li>
</ul>
</li>
<li><p>Array:</p>
<ul>
<li><p>List of one or more entries enclosed by square braces [].</p></li>
<li><p>Array elements are separated by commas.</p></li>
</ul>
</li>
<li><p>String:</p>
<ul>
<li><p>A character string enclosed by double quotation marks “”.</p></li>
</ul>
</li>
<li><p>Integer:</p>
<ul>
<li><p>A numeric integer value.</p></li>
</ul>
</li>
<li><p>Float:</p>
<ul>
<li><p>A numeric float value.</p></li>
</ul>
</li>
<li><p>Boolean:</p>
<ul>
<li><p>A boolean value (TRUE or FALSE).</p></li>
</ul>
</li>
<li><p>Threshold:</p>
<ul>
<li><p>A threshold type (&lt;, &lt;=, ==, !-, &gt;=, or &gt;) followed by a numeric value.</p></li>
<li><p>The threshold type may also be specified using two letter abbreviations
(lt, le, eq, ne, ge, gt).</p></li>
<li><p>Multiple thresholds may be combined by specifying the logic type of AND
(&amp;&amp;) or OR (||). For example, “&gt;=5&amp;&amp;&lt;=10” defines the numbers between 5
and 10 and “==1||==2” defines numbers exactly equal to 1 or 2.</p></li>
</ul>
</li>
<li><p>Percentile Thresholds:</p>
<ul>
<li><p>Thresholds may be defined as percentiles of the data being processed in
several places:</p>
<ul>
<li><p>In Point-Stat and Grid-Stat when setting “cat_thresh”, “wind_thresh”
and “cnt_thresh”.</p></li>
<li><p>In Wavelet-Stat when setting “cat_thresh”.</p></li>
<li><p>In MODE when setting “conv_thresh” and “merge_thresh”.</p></li>
<li><p>In Ensemble-Stat when setting “obs_thresh”.</p></li>
<li><p>When using the “censor_thresh” config option.</p></li>
<li><p>In the Stat-Analysis “-out_fcst_thresh” and “-out_obs_thresh” job
command options.</p></li>
<li><p>In the Gen-Vx-Mask “-thresh” command line option.</p></li>
</ul>
</li>
<li><p>The following percentile threshold types are supported:</p>
<ul>
<li><p>“SFP” for a percentile of the sample forecast values.
e.g. “&gt;SFP50” means greater than the 50-th forecast percentile.</p></li>
<li><p>“SOP” for a percentile of the sample observation values.
e.g. “&gt;SOP75” means greater than the 75-th observation percentile.</p></li>
<li><p>“SCP” for a percentile of the sample climatology values.
e.g. “&gt;SCP90” means greater than the 90-th climatology percentile.</p></li>
<li><p>“USP” for a user-specified percentile threshold.
e.g. “&lt;USP90(2.5)” means less than the 90-th percentile values which
the user has already determined to be 2.5 outside of MET.</p></li>
<li><p>“==FBIAS1” to automatically de-bias the data. This option must be
used in conjunction with a simple threshold in the other field.
For example, when “obs.cat_thresh = &gt;5.0” and
“fcst.cat_thresh = ==FBIAS1;”, MET applies the &gt;5.0 threshold to the
observations and then chooses a forecast threshold which results in a
frequency bias of 1.</p></li>
<li><p>“CDP” for climatological distribution percentile thresholds.
These thresholds require that the climatological mean and standard
deviation be defined using the climo_mean and climo_stdev config file
options, respectively. The categorical (cat_thresh), conditional
(cnt_thresh), or wind speed (wind_thresh) thresholds are defined
relative to the climatological distribution at each point. Therefore,
the actual numeric threshold applied can change for each point.
e.g. “&gt;CDP50” means greater than the 50-th percentile of the
climatological distribution for each point.</p></li>
</ul>
</li>
<li><p>When percentile thresholds of type SFP, SOP, SCP, or CDP are requested
for continuous filtering thresholds (cnt_thresh), wind speed thresholds
(wind_thresh), or observation filtering thresholds (obs_thresh in
ensemble_stat), the following special logic is applied. Percentile
thresholds of type equality are automatically converted to percentile
bins which span the values from 0 to 100.
For example, “==CDP25” is automatically expanded to 4 percentile bins:
&gt;=CDP0&amp;&amp;&lt;CDP25,&gt;=CDP25&amp;&amp;&lt;CDP50,&gt;=CDP50&amp;&amp;&lt;CDP75,&gt;=CDP75&amp;&amp;&lt;=CDP100</p></li>
<li><p>When sample percentile thresholds of type SFP, SOP, SCP, or FBIAS1 are
requested, MET recomputes the actual percentile that the threshold
represents. If the requested percentile and actual percentile differ by
more than 5%, a warning message is printed. This may occur when the
sample size is small or the data values are not truly continuous.</p></li>
<li><p>When percentile thresholds of type SFP, SOP, SCP, or USP are used, the
actual threshold value is appended to the FCST_THRESH and OBS_THRESH
output columns. For example, if the 90-th percentile of the current set
of forecast values is 3.5, then the requested threshold “&lt;=SFP90” is
written to the output as “&lt;=SFP90(3.5)”.</p></li>
<li><p>When parsing FCST_THRESH and OBS_THRESH columns, the Stat-Analysis tool
ignores the actual percentile values listed in parentheses.</p></li>
</ul>
</li>
<li><p>Piecewise-Linear Function (currently used only by MODE):</p>
<ul>
<li><p>A list of (x, y) points enclosed in parenthesis ().</p></li>
<li><p>The (x, y) points are <em>NOT</em> separated by commas.</p></li>
</ul>
</li>
<li><p>User-defined function of a single variable:</p>
<ul>
<li><p>Left side is a function name followed by variable name in parenthesis.</p></li>
<li><p>Right side is an equation which includes basic math functions (+,-,*,/),
built-in functions (listed below), or other user-defined functions.</p></li>
<li><p>Built-in functions include:
sin, cos, tan, sind, cosd, tand, asin, acos, atan, asind, acosd, atand,
atan2, atan2d, arg, argd, log, exp, log10, exp10, sqrt, abs, min, max,
mod, floor, ceil, step, nint, sign</p></li>
</ul>
</li>
</ul>
<p>The context of a configuration entry matters. If an entry cannot be found in
the expected dictionary, the MET tools recursively search for that entry in the
parent dictionaries, all the way up to the top-level configuration file
dictionary. If you’d like to apply the same setting across all cases, you can
simply specify it once at the top-level. Alternatively, you can specify a
setting at the appropriate dictionary level to have finer control over the
behavior.</p>
<p>In order to make the configuration files more readable, several descriptive
integer types have been defined in the ConfigConstants file. These integer
names may be used on the right-hand side for many configuration file entries.</p>
<p>Each of the configurable MET tools expects a certain set of configuration
entries. Examples of the MET configuration files can be found in data/config
and scripts/config.</p>
<p>When you pass a configuration file to a MET tool, the tool actually parses up
to four different configuration files in the following order:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Reads share/met/config/ConfigConstants to define constants.</p></li>
<li><p>If the tool produces PostScript output, it reads share/met/config/ConfigMapData to define the map data to be plotted.</p></li>
<li><p>Reads the default configuration file for the tool from share/met/config.</p></li>
<li><p>Reads the user-specified configuration file from the command line.</p></li>
</ol>
</div></blockquote>
<p>Many of the entries from step (3) are overwritten by the user-specified entries
from step (4). Therefore, the configuration file you pass in on the command
line really only needs to contain entries that differ from the defaults.</p>
<p>Any of the configuration entries may be overwritten by the user-specified
configuration file. For example, the map data to be plotted may be included in
the user-specified configuration file and override the default settings defined
in the share/met/config/ConfigMapData file.</p>
<p>The configuration file language supports the use of environment variables. They
are specified as ${ENV_VAR}, where ENV_VAR is the name of the environment
variable. When scripting up many calls to the MET tools, you may find it
convenient to use them. For example, when applying the same configuration to
the output from multiple models, consider defining the model name as an
environment variable which the controlling script sets prior to verifying the
output of each model. Setting MODEL to that environment variable enables you
to use one configuration file rather than maintianing many very similar ones.</p>
<p>An error in the syntax of a configuration file will result in an error from the
MET tool stating the location of the parsing error.</p>
<p>The MET_BASE variable is defined in the code at compilation time as the path
to the MET shared data. These are things like the default configuration files,
common polygons and color scales. MET_BASE may be used in the MET configuration
files when specifying paths and the appropriate path will be substituted in.
If MET_BASE is defined as an environment variable, its value will be used
instead of the one defined at compilation time.</p>
<p>The MET_OBS_ERROR_TABLE environment variable can be set to specify the location
of an ASCII file defining observation error information. The default table can
be found in the installed share/met/table_files/obs_error_table.txt. This
observation error logic is applied in Ensemble-Stat to perturb ensemble member
values and/or define observation bias corrections.</p>
<p>When processing point and gridded observations, Ensemble-Stat searches the table
to find the entry defining the observation error information. The table
consists of 15 columns and includes a header row defining each column. The
special string “ALL” is interpreted as a wildcard in these files. The first 6
columns (OBS_VAR, MESSAGE_TYPE, PB_REPORT_TYPE, IN_REPORT_TYPE, INSTRUMENT_TYPE,
and STATION_ID) may be set to a comma-separated list of strings to be matched.
In addition, the strings in the OBS_VAR column are interpreted as regular
expressions when searching for a match. For example, setting the OBS_VAR column
to ‘APCP_[0-9]+’ would match observations for both APCP_03 and APCP_24. The
HGT_RANGE, VAL_RANGE, and PRS_RANGE columns should either be set to “ALL” or
“BEG,END” where BEG and END specify the range of values to be used. The
INST_BIAS_SCALE and INST_BIAS_OFFSET columns define instrument bias adjustments
which are applied to the observation values. The DIST_TYPE and DIST_PARM
columns define the distribution from which random perturbations should be drawn
and applied to the ensemble member values. See the obs_error description below
for details on the supported error distributions. The last two columns, MIN and
MAX, define the bounds for the valid range of the bias-corrected observation
values and randomly perturbed ensemble member values. Values less than MIN are
reset to the mimimum value and values greater than MAX are reset to the maximum
value. A value of NA indicates that the variable is unbounded.</p>
<p>The MET_GRIB_TABLES environment variable can be set to specify the location of
custom GRIB tables. It can either be set to a specific file name or to a
directory containing custom GRIB tables files. These file names must begin with
a “grib1” or “grib2” prefix and end with a “.txt” suffix. Their format must
match the format used by the default MET GRIB table files, described below.
The custom GRIB tables are read prior to the default tables and their settings
take precedence.</p>
<p>At runtime, the MET tools read default GRIB tables from the installed
share/met/table_files directory, and their file formats are described below:</p>
<p>GRIB1 table files begin with “grib1” prefix and end with a “.txt” suffix.
The first line of the file must contain “GRIB1”.
The following lines consist of 4 integers followed by 3 strings:</p>
<div class="line-block">
<div class="line">Column 1: GRIB code (e.g. 11 for temperature)</div>
<div class="line">Column 2: parameter table version number</div>
<div class="line">Column 3: center id (e.g. 07 for US Weather Service- National Met. Center)</div>
<div class="line">Column 4: subcenter id</div>
<div class="line">Column 5: variable name</div>
<div class="line">Column 6: variable description</div>
<div class="line">Column 7: units</div>
<div class="line"><br /></div>
</div>
<p>References:</p>
<div class="line-block">
<div class="line"><a class="reference external" href="http://www.nco.ncep.noaa.gov/pmb/docs/on388">Office Note 388 GRIB1</a></div>
<div class="line"><a class="reference external" href="http://www.wmo.int/pages/prog/www/WMOCodes/Guides/GRIB/GRIB1-Contents.html">A Guide to the Code Form FM 92-IX Ext. GRIB Edition 1</a></div>
<div class="line"><br /></div>
</div>
<p>GRIB2 table files begin with “grib2” prefix and end with a “.txt” suffix.
The first line of the file must contain “GRIB2”.
The following lines consist of 8 integers followed by 3 strings.</p>
<div class="line-block">
<div class="line">Column 1:  Section 0 Discipline</div>
<div class="line">Column 2:  Section 1 Master Tables Version Number</div>
<div class="line">Column 3:  Section 1 Master Tables Version Number, low range of tables</div>
<div class="line">Column 4:  Section 1 Master Table Version Number, high range of tables</div>
<div class="line">Column 5:  Section 1 originating center</div>
<div class="line">Column 6:  Local Tables Version Number</div>
<div class="line">Column 7:  Section 4 Template 4.0 Parameter category</div>
<div class="line">Column 8:  Section 4 Template 4.0 Parameter number</div>
<div class="line">Column 9:  variable name</div>
<div class="line">Column 10: variable description</div>
<div class="line">Column 11: units</div>
<div class="line"><br /></div>
</div>
<p>References:</p>
<div class="line-block">
<div class="line"><a class="reference external" href="http://www.nco.ncep.noaa.gov/pmb/docs/grib2/grib2_doc">NCEP WMO GRIB2 Documentation</a></div>
<div class="line"><br /></div>
</div>
<div class="section" id="configuration-settings-used-by-the-met-tools">
<h2><span class="section-number">26.1. </span>Configuration settings used by the MET tools<a class="headerlink" href="#configuration-settings-used-by-the-met-tools" title="Permalink to this headline">¶</a></h2>
<div class="section" id="settings-common-to-multiple-tools">
<h3><span class="section-number">26.1.1. </span>Settings common to multiple tools<a class="headerlink" href="#settings-common-to-multiple-tools" title="Permalink to this headline">¶</a></h3>
<p><strong>exit_on_warning</strong></p>
<p>The “exit_on_warning” entry in ConfigConstants may be set to true or false.
If set to true and a MET tool encounters a warning, it will immediately exit
with bad status after writing the warning message.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>exit_on_warning = FALSE;
</pre></div>
</div>
<p><strong>nc_compression</strong></p>
<p>The “nc_compression” entry in ConfigConstants defines the compression level
for the NetCDF variables. Setting this option in the config file of one of
the tools overrides the default value set in ConfigConstants. The
environment variable MET_NC_COMPRESS overrides the compression level
from configuration file. The command line argument “-compress n” for some
tools overrides it.
The range is 0 to 9.</p>
<ul class="simple">
<li><p>0 is to disable the compression.</p></li>
<li><p>1 to 9: Lower number is faster, higher number for smaller files.</p></li>
</ul>
<p>WARNING: Selecting a high compression level may slow down the reading and
writing of NetCDF files within MET significantly.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>nc_compression = 0;
</pre></div>
</div>
<p><strong>output_precision</strong></p>
<p>The “output_precision” entry in ConfigConstants defines the precision
(number of significant decimal places) to be written to the ASCII output
files. Setting this option in the config file of one of the tools will
override the default value set in ConfigConstants.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>output_precision = 5;
</pre></div>
</div>
<p><strong>tmp_dir</strong></p>
<p>The “tmp_dir” entry in ConfigConstants defines the directory for the
temporary files. The directory must exist and be writable. The environment
variable MET_TMP_DIR overrides the default value at the configuration file.
Some tools override the temporary directory by the command line argument
“-tmp_dir &lt;diretory_name&gt;”.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>tmp_dir = &quot;/tmp&quot;;
</pre></div>
</div>
<p><strong>message_type_group_map</strong></p>
<p>The “message_type_group_map” entry is an array of dictionaries, each
containing a “key” string and “val” string. This defines a mapping of
message type group names to a comma-separated list of values. This map is
defined in the config files for PB2NC, Point-Stat, or Ensemble-Stat. Modify
this map to define sets of message types that should be processed together as
a group. The “SURFACE” entry must be present to define message types for
which surface verification logic should be applied.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>mesage_type_group_map = [
   { key = &quot;SURFACE&quot;; val = &quot;ADPSFC,SFCSHP,MSONET&quot;;               },
   { key = &quot;ANYAIR&quot;;  val = &quot;AIRCAR,AIRCFT&quot;;                      },
   { key = &quot;ANYSFC&quot;;  val = &quot;ADPSFC,SFCSHP,ADPUPA,PROFLR,MSONET&quot;; },
   { key = &quot;ONLYSF&quot;;  val = &quot;ADPSFC,SFCSHP&quot;;                      }
];
</pre></div>
</div>
<p><strong>message_type_map</strong></p>
<p>The “message_type_map” entry is an array of dictionaries, each containing
a “key” string and “val” string. This defines a mapping of input strings
to output message types. This mapping is applied in ASCII2NC when
converting input little_r report types to output message types. This mapping
is also supported in PBN2NC as a way of renaming input PREPBUFR message
types.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>message_type_map = [
   { key = &quot;FM-12 SYNOP&quot;;  val = &quot;ADPSFC&quot;; },
   { key = &quot;FM-13 SHIP&quot;;   val = &quot;SFCSHP&quot;; },
   { key = &quot;FM-15 METAR&quot;;  val = &quot;ADPSFC&quot;; },
   { key = &quot;FM-18 BUOY&quot;;   val = &quot;SFCSHP&quot;; },
   { key = &quot;FM-281 QSCAT&quot;; val = &quot;ASCATW&quot;; },
   { key = &quot;FM-32 PILOT&quot;;  val = &quot;ADPUPA&quot;; },
   { key = &quot;FM-35 TEMP&quot;;   val = &quot;ADPUPA&quot;; },
   { key = &quot;FM-88 SATOB&quot;;  val = &quot;SATWND&quot;; },
   { key = &quot;FM-97 ACARS&quot;;  val = &quot;AIRCFT&quot;; }
];
</pre></div>
</div>
<p><strong>model</strong></p>
<p>The “model” entry specifies a name for the model being verified. This name
is written to the MODEL column of the ASCII output generated. If you’re
verifying multiple models, you should choose descriptive model names (no
whitespace) to distinguish between their output.
e.g. model = “GFS”;</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>model = &quot;WRF&quot;;
</pre></div>
</div>
<p><strong>desc</strong></p>
<p>The “desc” entry specifies a user-specified description for each verification
task. This string is written to the DESC column of the ASCII output
generated. It may be set separately in each “obs.field” verification task
entry or simply once at the top level of the configuration file. If you’re
verifying the same field multiple times with different quality control
flags, you should choose description strings (no whitespace) to distinguish
between their output.
e.g. desc = “QC_9”;</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>desc = &quot;NA&quot;;
</pre></div>
</div>
<p><strong>obtype</strong></p>
<p>The “obtype” entry specifies a name to describe the type of verifying gridded
observation used. This name is written to the OBTYPE column in the ASCII
output generated. If you’re using multiple types of verifying observations,
you should choose a descriptive name (no whitespace) to distinguish between
their output. When verifying against point observations the point
observation message type value is written to the OBTYPE column. Otherwise,
the configuration file obtype value is written.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>obtype = &quot;ANALYS&quot;;
</pre></div>
</div>
<p><strong>regrid</strong></p>
<p>The “regrid” entry is a dictionary containing information about how to handle
input gridded data files. The “regrid” entry specifies regridding logic
using the following entries:</p>
<ul>
<li><p>The “to_grid” entry may be set to NONE, FCST, OBS, a named grid, the path
to a gridded data file defining the grid, or an explicit grid specification
string.</p>
<ul class="simple">
<li><p>to_grid = NONE;   To disable regridding.</p></li>
<li><p>to_grid = FCST;   To regrid observations to the forecast grid.</p></li>
<li><p>to_grid = OBS;    To regrid forecasts to the observation grid.</p></li>
<li><p>to_grid = “G218”; To regrid both to a named grid.</p></li>
<li><p>to_grid = “path”; To regrid both to a grid defined by a file.</p></li>
<li><p>to_grid = “spec”; To define a grid specified as follows:</p>
<ul>
<li><p>lambert Nx Ny lat_ll lon_ll lon_orient D_km R_km standard_parallel_1
[standard_parallel_2] N|S</p></li>
<li><p>stereo Nx Ny lat_ll lon_ll lon_orient D_km R_km lat_scale N|S</p></li>
<li><p>latlon Nx Ny lat_ll lon_ll delta_lat delta_lon</p></li>
<li><p>mercator Nx Ny lat_ll lon_ll lat_ur lon_ur</p></li>
<li><p>gaussian lon_zero Nx Ny</p></li>
</ul>
</li>
</ul>
</li>
<li><p>The “vld_thresh” entry specifies a proportion between 0 and 1 to define
the required ratio of valid data points. When regridding, compute
a ratio of the number of valid data points to the total number of
points in the neighborhood. If that ratio is less than this threshold,
write bad data for the current point.</p></li>
<li><p>The “method” entry defines the regridding method to be used.</p>
<ul>
<li><p>Valid regridding methods:</p>
<ul class="simple">
<li><p>MIN         for the minimum value</p></li>
<li><p>MAX         for the maximum value</p></li>
<li><p>MEDIAN      for the median value</p></li>
<li><p>UW_MEAN     for the unweighted average value</p></li>
<li><p>DW_MEAN     for the distance-weighted average value (weight =
distance^-2)</p></li>
<li><p>AW_MEAN     for an area-weighted mean when regridding from
high to low resolution grids (width = 1)</p></li>
<li><p>LS_FIT      for a least-squares fit</p></li>
<li><p>BILIN       for bilinear interpolation (width = 2)</p></li>
<li><p>NEAREST     for the nearest grid point (width = 1)</p></li>
<li><p>BUDGET      for the mass-conserving budget interpolation</p></li>
<li><p>FORCE       to compare gridded data directly with no interpolation
as long as the grid x and y dimensions match.</p></li>
<li><p>UPPER_LEFT  for the upper left grid point (width = 1)</p></li>
<li><p>UPPER_RIGHT for the upper right grid point (width = 1)</p></li>
<li><p>LOWER_RIGHT for the lower right grid point (width = 1)</p></li>
<li><p>LOWER_LEFT  for the lower left grid point (width = 1)</p></li>
<li><p>MAXGAUSS    to compute the maximum value in the neighborhood
and apply a Gaussian smoother to the result</p></li>
</ul>
<p>The BEST and GEOG_MATCH interpolation options are not valid for regridding.</p>
</li>
</ul>
</li>
<li><p>The “width” entry specifies a regridding width, when applicable.
- width = 4;    To regrid using a 4x4 box or circle with diameter 4.</p></li>
<li><p>The “shape” entry defines the shape of the neighborhood.
Valid values are “SQUARE” or “CIRCLE”</p></li>
<li><p>The “gaussian_dx” entry specifies a delta distance for Gaussian
smoothing. The default is 81.271. Ignored if not Gaussian method.</p></li>
<li><p>The “gaussian_radius” entry defines the radius of influence for Gaussian
smoothing. The default is 120. Ignored if not Gaussian method.</p></li>
<li><p>The “gaussian_dx” and “gaussian_radius” settings must be in the same
units, such as kilometers or degress.  Their ratio
(sigma = gaussian_radius / gaussian_dx) determines the Guassian weighting
function.</p></li>
<li><p>The “convert”, “censor_thresh”, and “censor_val” entries are described
below.  When specified, these operations are applied to the output of the
regridding step.  The conversion operation is applied first, followed by
the censoring operation.</p></li>
</ul>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>regrid = {
   to_grid         = NONE;
   method          = NEAREST;
   width           = 1;
   vld_thresh      = 0.5;
   shape           = SQUARE;
   gaussian_dx     = 81.271;
   gaussian_radius = 120;
   convert(x)      = x;
   censor_thresh   = [];
   censor_val      = [];
}
</pre></div>
</div>
<p><strong>fcst</strong></p>
<p>The “fcst” entry is a dictionary containing information about the field(s)
to be verified. This dictionary may include the following entries:</p>
<ul>
<li><p>The “field” entry is an array of dictionaries, each specifying a
verification task. Each of these dictionaries may include:</p>
<ul>
<li><p>The “name” entry specifies a name for the field.</p></li>
<li><p>The “level” entry specifies level information for the field.</p></li>
<li><p>Setting “name” and “level” is file-format specific. See below.</p></li>
<li><p>The “prob” entry in the forecast dictionary defines probability
information. It may either be set as a boolean (i.e. TRUE or FALSE)
or as a dictionary defining probabilistic field information.</p>
<p>When set as a boolean to TRUE, it indicates that the “fcst.field” data
should be treated as probabilities. For example, when verifying the
probabilistic NetCDF output of Ensemble-Stat, one could configure the
Grid-Stat or Point-Stat tools as follows:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>fcst = {
   field = [ { name  = &quot;APCP_24_A24_ENS_FREQ_gt0.0&quot;;
               level = &quot;(*,*)&quot;;
               prob  = TRUE; } ];
   }
</pre></div>
</div>
<p>Setting “prob = TRUE” indicates that the “APCP_24_A24_ENS_FREQ_gt0.0”
data should be processed as probabilities.</p>
<p>When set as a dictionary, it defines the probabilistic field to be
used. For example, when verifying GRIB files containing probabilistic
data,  one could configure the Grid-Stat or Point-Stat tools as
follows:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>fcst = {
   field = [ { name = &quot;PROB&quot;; level = &quot;A24&quot;;
               prob = { name = &quot;APCP&quot;; thresh_lo = 2.54; } },
             { name = &quot;PROB&quot;; level = &quot;P850&quot;;
               prob = { name = &quot;TMP&quot;; thresh_hi = 273; } } ];
}
</pre></div>
</div>
<p>The example above selects two probabilistic fields. In both, “name”
is set to “PROB”, the GRIB abbreviation for probabilities. The “level”
entry defines the level information (i.e. “A24” for a 24-hour
accumulation and “P850” for 850mb). The “prob” dictionary defines the
event for which the probability is defined. The “thresh_lo”
(i.e. APCP &gt; 2.54) and/or “thresh_hi” (i.e. TMP &lt; 273) entries are
used to define the event threshold(s).</p>
<p>Probability fields should contain values in the range
[0, 1] or [0, 100]. However, when MET encounters a probability field
with a range [0, 100], it will automatically rescale it to be [0, 1]
before applying the probabilistic verification methods.</p>
</li>
<li><p>Set “prob_as_scalar = TRUE” to override the processing of probability
data. When the “prob” entry is set as a dictionary to define the
field of interest, setting “prob_as_scalar = TRUE” indicates that this
data should be processed as regular scalars rather than probabilities.
For example, this option can be used to compute traditional 2x2
contingency tables and neighborhood verification statistics for
probability data. It can also be used to compare two probability
fields directly. When this flag is set, probability values are
automatically rescaled from the range [0, 100] to [0, 1].</p></li>
<li><p>The “convert” entry is a user-defined function of a single variable
for processing input data values. Any input values that are not bad
data are replaced by the value of this function. The convert function
is applied prior to regridding or thresholding. This function may
include any of the built-in math functions (e.g. sqrt, log10)
described above.
Several standard unit conversion functions are already defined in
data/config/ConfigConstants.
Examples of user-defined conversion functions include:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>convert(x) = 2*x;
convert(x) = x^2;
convert(a) = log10(a);
convert(a) = a^10;
convert(t) = max(1, sqrt(abs(t)));
convert(x) = K_to_C(x); where K_to_C(x) is defined in
                        ConfigConstants
</pre></div>
</div>
</li>
<li><p>The “censor_thresh” entry is an array of thresholds to be applied
to the input data. The “censor_val” entry is an array of numbers
and must be the same length as “censor_thresh”. These arguments must
appear together in the correct format (threshold and number). For each
censor threshold, any input values meeting the threshold criteria will
be reset to the corresponding censor value. An empty list indicates
that no censoring should be performed. The censoring logic is applied
prior to any regridding but after the convert function. All statistics
are computed on the censored data. These entries may be used to apply
quality control logic by resetting data outside of an expected range
to the bad data value of -9999. These entries are not indicated in the
metadata of any output files, but the user can set the “desc” entry
accordingly.</p>
<p>Examples of user-defined conversion functions include:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>censor_thresh = [ &gt;12000 ];
censor_val    = [ 12000 ];
</pre></div>
</div>
</li>
<li><p>Several configuration options are provided to override and correct the
metadata read from the input file. The supported options are listed
below:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>// Data attributes
set_attr_name      = &quot;string&quot;;
set_attr_level     = &quot;string&quot;;
set_attr_units     = &quot;string&quot;;
set_attr_long_name = &quot;string&quot;;

// Time attributes
set_attr_init  = &quot;YYYYMMDD[_HH[MMSS]]&quot;;
set_attr_valid = &quot;YYYYMMDD[_HH[MMSS]]&quot;;
set_attr_lead  = &quot;HH[MMSS]&quot;;
set_attr_accum = &quot;HH[MMSS]&quot;;

// Grid definition (must match the actual data dimensions)
set_attr_grid  = &quot;named grid or grid specification string&quot;;

// Flags
is_precipitation     = boolean;
is_specific_humidity = boolean;
is_u_wind            = boolean;
is_v_wind            = boolean;
is_grid_relative     = boolean;
is_wind_speed        = boolean;
is_wind_direction    = boolean;
is_prob              = boolean;
</pre></div>
</div>
</li>
<li><p>The “cat_thresh” entry is an array of thresholds to be used when
computing categorical statistics.</p></li>
<li><p>The “cnt_thresh” entry is an array of thresholds for filtering
data prior to computing continuous statistics and partial sums.</p></li>
<li><p>The “cnt_logic” entry may be set to UNION, INTERSECTION, or SYMDIFF
and controls the logic for how the forecast and observed cnt_thresh
settings are combined when filtering matched pairs of forecast and
observed values.</p></li>
</ul>
</li>
<li><p>The “file_type” entry specifies the input gridded data file type rather
than letting the code determine it. MET determines the file type by
checking for known suffixes and examining the file contents. Use this
option to override the code’s choice. The valid file_type values are
listed the “data/config/ConfigConstants” file and are described below.
This entry should be defined within the “fcst” and/or “obs” dictionaries.
For example:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>fcst = {
   file_type = GRIB1;         GRIB version 1
   file_type = GRIB2;         GRIB version 2
   file_type = NETCDF_MET;    NetCDF created by another MET tool
   file_type = NETCDF_PINT;   NetCDF created by running the p_interp
                              or wrf_interp utility on WRF output.
                              May be used to read unstaggered raw WRF
                              NetCDF output at the surface or a
                              single model level.
   file_type = NETCDF_NCCF;   NetCDF following the Climate Forecast
                              (CF) convention.
   file_type = PYTHON_NUMPY;  Run a Python script to load data into
                              a NumPy array.
   file_type = PYTHON_XARRAY; Run a Python script to load data into
                              an xarray object.
}
</pre></div>
</div>
</li>
<li><p>The “wind_thresh” entry is an array of thresholds used to filter wind
speed values when computing VL1L2 vector partial sums. Only those U/V
pairs that meet this wind speed criteria will be included in the sums.
Setting this threshold to NA will result in all U/V pairs being used.</p></li>
<li><p>The “wind_logic” entry may be set to UNION, INTERSECTION, or SYMDIFF
and controls the logic for how the forecast and observed wind_thresh
settings are combined when filtering matched pairs of forecast and
observed wind speeds.</p></li>
<li><p>The “eclv_points” entry specifies the economic cost/loss ratio points
to be evaluated. For each cost/loss ratio specified, the relative value
will be computed and written to the ECLV output line. This entry may
either be specified as an array of numbers between 0 and 1 or as a single
number. For an array, each array entry will be evaluated. For a single
number, all evenly spaced points between 0 and 1 will be evaluated, where
eclv_points defines the spacing. Cost/loss values are omitted for
ratios of 0.0 and 1.0 since they are undefined.</p></li>
<li><p>The “init_time” entry specifies the initialization time in
YYYYMMDD[_HH[MMSS]]
format. This entry can be included in the “fcst” entry as shown below or
included in the “field” entry if the user would like to use different
initialization times for different fields.</p></li>
<li><p>The “valid_time” entry specifies the valid time in YYYYMMDD[_HH[MMSS]]
format. This entry can be included in the “fcst” entry as shown below or
included in the “field” entry if the user would like to use different
valid times for different fields.</p></li>
<li><p>The “lead_time” entry specifies the lead time in HH[MMSS]
format. This entry can be included in the “fcst” entry as shown below or
included in the “field” entry if the user would like to use different
lead times for different fields.</p></li>
</ul>
<p>It is only necessary to use the “init_time”, “valid_time”, and/or “lead_time”
settings when verifying a file containing data for multiple output times.
For example, to verify a GRIB file containing data for many lead times, you
could use “lead_time” to specify the record to be verified.</p>
<p>File-format specific settings for the “field” entry:</p>
<blockquote>
<div><ul>
<li><p>GRIB1 and GRIB2:</p>
<ul>
<li><p>For custom GRIB tables, see note about MET_GRIB_TABLES.</p></li>
<li><p>The “name” entry specifies a GRIB code number or abbreviation.</p>
<ul class="simple">
<li><p><a class="reference external" href="http://www.nco.ncep.noaa.gov/pmb/docs/on388/table2.html">GRIB1 Product Definition Section</a></p></li>
<li><p><a class="reference external" href="http://www.nco.ncep.noaa.gov/pmb/docs/grib2/grib2_doc">GRIB2 Product Definition Section</a></p></li>
</ul>
</li>
<li><p>The “level” entry specifies a level type and value:</p>
<ul class="simple">
<li><p>ANNN for accumulation interval NNN</p></li>
<li><p>ZNNN for vertical level NNN</p></li>
<li><p>ZNNN-NNN for a range of vertical levels</p></li>
<li><p>PNNN for pressure level NNN in hPa</p></li>
<li><p>PNNN-NNN for a range of pressure levels in hPa</p></li>
<li><p>LNNN for a generic level type</p></li>
<li><p>RNNN for a specific GRIB record number</p></li>
</ul>
</li>
<li><p>The “GRIB_lvl_typ” entry is an integer specifying the level type.</p></li>
<li><p>The “GRIB_lvl_val1” and “GRIB_lvl_val2” entries are floats specifying
the first and second level values.</p></li>
<li><p>The “GRIB_ens” entry is a string specifying NCEP’s usage of the
extended PDS for ensembles. Set to “hi_res_ctl”, “low_res_ctl”,
“+n”, or “-n”, for the n-th ensemble member.</p></li>
<li><p>The “GRIB1_ptv” entry is an integer specifying the GRIB1 parameter
table version number.</p></li>
<li><p>The “GRIB1_code” entry is an integer specifying the GRIB1 code (wgrib
kpds5 value).</p></li>
<li><p>The “GRIB1_center” is an integer specifying the originating center.</p></li>
<li><p>The “GRIB1_subcenter” is an integer specifying the originating
subcenter.</p></li>
<li><p>The “GRIB1_tri” is an integer specifying the time range indicator.</p></li>
<li><p>The “GRIB2_mtab” is an integer specifying the master table number.</p></li>
<li><p>The “GRIB2_ltab” is an integer specifying the local table number.</p></li>
<li><p>The “GRIB2_disc” is an integer specifying the GRIB2 discipline code.</p></li>
<li><p>The “GRIB2_parm_cat” is an integer specifying the parameter category
code.</p></li>
<li><p>The “GRIB2_parm” is an integer specifying the parameter code.</p></li>
<li><p>The “GRIB2_pdt” is an integer specifying the product definition
template (Table 4.0).</p></li>
<li><p>The “GRIB2_process” is an integer specifying the generating process
(Table 4.3).</p></li>
<li><p>The “GRIB2_cntr” is an integer specifying the originating center.</p></li>
<li><p>The “GRIB2_ens_type” is an integer specifying the ensemble type
(Table 4.6).</p></li>
<li><p>The “GRIB2_der_type” is an integer specifying the derived product
type (Table 4.7).</p></li>
<li><p>The “GRIB2_stat_type” is an integer specifying the statistical
processing type (Table 4.10).</p></li>
<li><p>The “GRIB2_ipdtmpl_index” and “GRIB2_ipdtmpl_val” entries are arrays
of integers which specify the product description template values to
be used. The indices are 0-based. For example, use the following to
request a GRIB2 record whose 9-th and 27-th product description
template values are 1 and 2, respectively:</p>
<p>GRIB2_ipdtmpl_index=[8, 26]; GRIB2_ipdtmpl_val=[1, 2];</p>
</li>
</ul>
</li>
<li><p>NetCDF (from MET tools, CF-compliant, p_interp, and wrf_interp):</p>
<ul>
<li><p>The “name” entry specifies the NetCDF variable name.</p></li>
<li><p>The “level” entry specifies the dimensions to be used:</p>
<ul class="simple">
<li><p>(i,…,j,*,*) for a single field, where i,…,j specifies fixed
dimension values and <em>,</em> specifies the two dimensions for the
gridded field. For example:</p></li>
</ul>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>field = [
     {
       name       = &quot;QVAPOR&quot;;
       level      = &quot;(0,5,*,*)&quot;;
     },
     {
       name       = &quot;TMP_P850_ENS_MEAN&quot;;
       level      = [ &quot;(*,*)&quot; ];
     }
   ];
</pre></div>
</div>
</li>
</ul>
</li>
<li><p>Python (using PYTHON_NUMPY or PYTHON_XARRAY):</p>
<ul class="simple">
<li><p>The Python interface for MET is described in Appendix F of the MET
User’s Guide.</p></li>
<li><p>Two methods for specifying the Python command and input file name
are supported. For tools which read a single gridded forecast and/or
observation file, both options work. However, only the second option
is supported for tools which read multiple gridded data files, such
as Ensemble-Stat, Series-Analysis, and MTD.</p></li>
</ul>
<p>Option 1:</p>
<blockquote>
<div><ul>
<li><p>On the command line, replace the path to the input gridded data
file with the constant string PYTHON_NUMPY or PYTHON_XARRAY.</p></li>
<li><p>Specify the configuration “name” entry as the Python command to be
executed to read the data.</p></li>
<li><p>The “level” entry is not required for Python.</p>
<p>For example:</p>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>field = [
  { name = &quot;read_ascii_numpy.py data/python/fcst.txt FCST&quot;; }
];
</pre></div>
</div>
</div></blockquote>
</li>
</ul>
</div></blockquote>
<p>Option 2:</p>
<blockquote>
<div><ul>
<li><p>On the command line, leave the path to the input gridded data
as is.</p></li>
<li><p>Set the configuration “file_type” entry to the constant
PYTHON_NUMPY or PYTHON_XARRAY.</p></li>
<li><p>Specify the configuration “name” entry as the Python command to be
executed to read the data, but replace the input gridded data file
with the constant MET_PYTHON_INPUT_ARG.</p></li>
<li><p>The “level” entry is not required for Python.</p>
<p>For example:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>file_type = PYTHON_NUMPY;
field     = [
  { name = &quot;read_ascii_numpy.py MET_PYTHON_INPUT_ARG FCST&quot;; }
];
</pre></div>
</div>
</li>
</ul>
</div></blockquote>
</li>
</ul>
</div></blockquote>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>fcst = {
   censor_thresh = [];
   censor_val    = [];
   cnt_thresh    = [ NA ];
   cnt_logic     = UNION;
   wind_thresh   = [ NA ];
   wind_logic    = UNION;
   eclv_points   = 0.05;
   message_type  = [ &quot;ADPSFC&quot; ];
   init_time     = &quot;20120619_12&quot;;
   valid_time    = &quot;20120620_00&quot;;
   lead_time     = &quot;12&quot;;

   field = [
      {
        name       = &quot;APCP&quot;;
        level      = [ &quot;A03&quot; ];
        cat_thresh = [ &gt;0.0, &gt;=5.0 ];
      }
   ];
}
</pre></div>
</div>
<p><strong>obs</strong></p>
<p>The “obs” entry specifies the same type of information as “fcst”, but for
the observation data. It will often be set to the same things as “fcst”,
as shown in the example below. However, when comparing forecast and
observation files of different format types, this entry will need to be set
in a non-trivial way. The length of the “obs.field” array must match the
length of the “fcst.field” array.  For example:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>obs = fcst;
</pre></div>
</div>
<p>or</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>fcst = {
  censor_thresh = [];
  censor_val    = [];
  cnt_thresh    = [ NA ];
  cnt_logic     = UNION;
  wind_thresh   = [ NA ];
  wind_logic    = UNION;

  field = [
     {
        name       = &quot;PWAT&quot;;
        level      = [ &quot;L0&quot; ];
        cat_thresh = [ &gt;2.5 ];
     }
   ];
}


obs = {
  censor_thresh = [];
  censor_val    = [];
  cnt_thresh    = [ NA ];
  cnt_logic     = UNION;
  wind_thresh   = [ NA ];
  wind_logic    = UNION;

  field = [
     {
        name       = &quot;IWV&quot;;
        level      = [ &quot;L0&quot; ];
        cat_thresh = [ &gt;25.0 ];
     }
   ];
}
</pre></div>
</div>
<ul>
<li><p>The “message_type” entry is an array of point observation message types
to be used. This only applies to the tools that verify against point
observations. This may be specified once at the top-level “obs”
dictionary or separately for each “field” array element. In the example
shown above, this is specified in the “fcst” dictionary and copied to
“obs”.</p></li>
<li><p>Simplified vertical level matching logic is applied for surface message
types. Observations for the following message types are assumed to be at
the surface, as defined by the default message_type_group_map:
ADPSFC, SFCSHP, MSONET</p></li>
<li><p>The “message_type” would be placed in the “field” array element if more
than one “message_type” entry is desired within the config file. For example:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>fcst = {
    censor_thresh = [];
    censor_val    = [];
    cnt_thresh    = [ NA ];
    cnt_logic     = UNION;
    wind_thresh   = [ NA ];
    wind_logic    = UNION;

    field = [
       {
         message_type = [ &quot;ADPUPA&quot; ];
         sid_inc      = [];
         sid_exc      = [];
         name         = &quot;TMP&quot;;
         level        = [ &quot;P250&quot;, &quot;P500&quot;, &quot;P700&quot;, &quot;P850&quot;, &quot;P1000&quot; ];
         cat_thresh   = [ &lt;=273.0 ];
       },
       {
         message_type = [ &quot;ADPSFC&quot; ];
         sid_inc      = [];
         sid_exc      = [ &quot;KDEN&quot;, &quot;KDET&quot; ];
         name         = &quot;TMP&quot;;
         level        = [ &quot;Z2&quot; ];
         cat_thresh   = [ &lt;=273.0 ];
       }
    ];
  }
</pre></div>
</div>
</li>
</ul>
<blockquote>
<div><ul class="simple">
<li><p>The “sid_inc” entry is an array of station ID groups indicating which
station ID’s should be included in the verification task. If specified,
only those station ID’s appearing in the list will be included.  Note
that filtering by station ID may also be accomplished using the “mask.sid”
option. However, when using the “sid_inc” option, statistics are reported
separately for each masking region.</p></li>
<li><p>The “sid_exc” entry is an array of station ID groups indicating which
station ID’s should be excluded from the verification task.</p></li>
<li><p>Each element in the “sid_inc” and “sid_exc” arrays is either the name of
a single station ID or the full path to a station ID group file name.
A station ID group file consists of a name for the group followed by a
list of station ID’s. All of the station ID’s indicated will be concatenated
into one long list of station ID’s to be included or excluded.</p></li>
<li><p>As with “message_type” above, the “sid_inc” and “sid_exc” settings can be
placed in the in the “field” array element to control which station ID’s
are included or excluded for each verification task.</p></li>
</ul>
</div></blockquote>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>obs = fcst;
</pre></div>
</div>
<p><strong>climo_mean</strong></p>
<p>The “climo_mean” dictionary specifies climatology mean data to be read by the
Grid-Stat, Point-Stat, Ensemble-Stat, and Series-Analysis tools. It consists
of several entires defining the climatology file names and fields to be used.</p>
<ul class="simple">
<li><p>The “file_names” entry specifies one or more file names containing
the gridded climatology data to be used.</p></li>
<li><p>The “field” entry is an array of dictionaries, specified the same
way as those in the “fcst” and “obs” dictionaries. If the array has
length zero, not climatology data will be read and all climatology
statistics will be written as missing data. Otherwise, the array
length must match the length of “field” in the “fcst” and “obs”
dictionaries.</p></li>
<li><p>The “regrid” dictionary defines how the climatology data should be
regridded to the verification domain.</p></li>
<li><p>The “time_interp_method” entry specifies how the climatology data should
be interpolated in time to the forecast valid time:</p></li>
</ul>
<blockquote>
<div><ul class="simple">
<li><p>NEAREST for data closest in time</p></li>
<li><p>UW_MEAN for average of data before and after</p></li>
<li><p>DW_MEAN for linear interpolation in time of data before and after</p></li>
</ul>
</div></blockquote>
<ul class="simple">
<li><p>The “day_interval” entry is an integer specifying the spacing in days of
the climatology data. Use 31 for monthly data or 1 for daily data.
Use “NA” if the timing of the climatology data should not be checked.</p></li>
<li><p>The “hour_interval” entry is an integer specifying the spacing in hours of
the climatology data for each day. This should be set between 0 and 24,
with 6 and 12 being common choices. Use “NA” if the timing of the
climatology data should not be checked.</p></li>
<li><p>The “day_interval” and “hour_interval” entries replace the deprecated
entries “match_month”, “match_day”, and “time_step”.</p></li>
</ul>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>climo_mean = {

   file_name = [ &quot;/path/to/climatological/mean/files&quot; ];
   field     = [];

   regrid = {
      method     = NEAREST;
      width      = 1;
      vld_thresh = 0.5;
   }

   time_interp_method = DW_MEAN;
   day_interval       = 31;
   hour_interal       = 6;
}
</pre></div>
</div>
<p><strong>climo_stdev</strong></p>
<p>The “climo_stdev” dictionary specifies climatology standard deviation data to
be read by the Grid-Stat, Point-Stat, Ensemble-Stat, and Series-Analysis
tools. The “climo_mean” and “climo_stdev” data define the climatological
distribution for each grid point, assuming normality. These climatological
distributions are used in two ways:</p>
<ol class="arabic simple">
<li><p>To define climatological distribution percentile (CDP) thresholds which
can be used as categorical (cat_thresh), continuous (cnt_thresh), or wind
speed (wind_thresh) thresholds.</p></li>
<li><p>To subset matched pairs into climatological bins based on where the
observation value falls within the climatological distribution. See the
“climo_cdf” dictionary.</p></li>
</ol>
<p>This dictionary is identical to the “climo_mean” dictionary described above
but points to files containing climatological standard deviation values
rather than means. In the example below, this dictionary is set by copying
over the “climo_mean” setting and then updating the “file_name” entry.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>climo_stdev = climo_mean;
climo_stdev = {
   file_name = [ &quot;/path/to/climatological/standard/deviation/files&quot; ];
}
</pre></div>
</div>
<p><strong>climo_cdf</strong></p>
<p>The “climo_cdf” dictionary specifies how the the climatological mean
(“climo_mean”) and standard deviation (“climo_stdev”) data are used to
evaluate model performance relative to where the observation value falls
within the climatological distribution. This dictionary consists of 3
entries:</p>
<ol class="arabic simple">
<li><p>The “cdf_bins” entry defines the climatological bins either as an integer
or an array of floats between 0 and 1.</p></li>
<li><p>The “center_bins” entry may be set to TRUE or FALSE.</p></li>
<li><p>The “write_bins” entry may be set to TRUE or FALSE.</p></li>
</ol>
<p>MET uses the climatological mean and standard deviation to construct a normal
PDF at each observation location. The total area under the PDF is 1, and the
climatological CDF value is computed as the area of the PDF to the left of
the observation value. Since the CDF is a value between 0 and 1, the CDF
bins must span that same range.</p>
<p>When “cdf_bins” is set to an array of floats, they explicitly define the
climatological bins. The array must begin with 0.0 and end with 1.0.
For example:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>cdf_bins = [ 0.0, 0.10, 0.25, 0.75, 0.90, 1.0 ];
</pre></div>
</div>
<p>When “cdf_bins” is set to an integer, it defines the number of bins to be
used. The “center_bins” flag indicates whether or not the bins should be
centered on 0.5. An odd number of bins can be centered or uncentered while
an even number of bins can only be  uncentered. For example:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>4 uncentered bins (cdf_bins = 4; center_bins = FALSE;) yields:
  0.0, 0.25, 0.50, 0.75, 1.0
5 uncentered bins (cdf_bins = 5; center_bins = FALSE;) yields:
  0.0, 0.2, 0.4, 0.6, 0.8, 0.9, 1.0
5   centered bins (cdf_bins = 5; center_bins = TRUE;) yields:
  0.0, 0.125, 0.375, 0.625, 0.875, 1.0
</pre></div>
</div>
<p>When multiple climatological bins are used, statistics are computed
separately for each bin, and the average of the statistics across those bins
is written to the output. When “write_bins” is true, the statistics for each
bin are also written to the output. The bin number is appended to the
contents of the VX_MASK output column.</p>
<p>Setting the number of bins to 1 effectively disables this logic by grouping
all pairs into a single climatological bin.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>climo_cdf = {
   cdf_bins    = 11;    or an array of floats
   center_bins = TRUE;  or FALSE
   write_bins  = FALSE; or TRUE
}
</pre></div>
</div>
<p><strong>climatology data for probability forecasts</strong></p>
<p>When specifying climatology data for probability forecasts, either supply a
probabilistic “climo_mean” field or non-probabilistic “climo_mean” and
“climo_stdev” fields from which a normal approximation of the climatological
probabilities should be derived.</p>
<p>When “climo_mean” is set to a probability field with a range of [0, 1] and
“climo_stdev” is unset, the MET tools use the “climo_mean” probability values
directly to compute Brier Skill Score (BSS).</p>
<p>When “climo_mean” and “climo_stdev” are both set to non-probability fields,
the MET tools use the mean, standard deviation, and observation event
threshold to derive a normal approximation of the climatological
probabilities. Those derived probability values are used to compute BSS.</p>
<p><strong>mask_missing_flag</strong></p>
<p>The “mask_missing_flag” entry specifies how missing data should be handled
in the Wavelet-Stat and MODE tools:</p>
<blockquote>
<div><ul class="simple">
<li><p>“NONE” to perform no masking of missing data</p></li>
<li><p>“FCST” to mask the forecast field with missing observation data</p></li>
<li><p>“OBS” to mask the observation field with missing forecast data</p></li>
<li><p>“BOTH” to mask both fields with missing data from the other</p></li>
</ul>
</div></blockquote>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>mask_missing_flag = BOTH;
</pre></div>
</div>
<p><strong>obs_window</strong></p>
<p>The “obs_window” entry is a dictionary specifying a beginning (“beg”
entry) and ending (“end” entry) time offset values in seconds. It defines
the time window over which observations are retained for scoring. These time
offsets are defined relative to a reference time t, as [t+beg, t+end].
In PB2NC, the reference time is the PREPBUFR files center time. In
Point-Stat and Ensemble-Stat, the reference time is the forecast valid time.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>obs_window = {
   beg = -5400;
   end =  5400;
}
</pre></div>
</div>
<p><strong>mask</strong></p>
<p>The “mask” entry is a dictionary that specifies the verification masking
regions to be used when computing statistics. Each mask defines a
geographic extent, and any matched pairs falling inside that area will be
used in the computation of statistics. Masking regions may be specified
in the following ways:</p>
<ul>
<li><p>The “grid” entry is an array of named grids. It contains a
comma-separated list of pre-defined NCEP grids over which to perform
verification. An empty list indicates that no masking grids should be
used. The standard NCEP grids are named “GNNN” where NNN indicates the
three digit grid number. Supplying a value of “FULL” indicates that the
verification should be performed over the entire grid on which the data
resides.
See: <a class="reference external" href="http://www.nco.ncep.noaa.gov/pmb/docs/on388/tableb.html">ON388 - TABLE B, GRID IDENTIFICATION (PDS Octet 7), MASTER LIST OF NCEP STORAGE GRIDS, GRIB Edition 1 (FM92)</a>.
The “grid” entry can be the gridded data file defining grid.</p></li>
<li><p>The “poly” entry contains a comma-separated list of files that define
verification masking regions. These masking regions may be specified in
two ways: as a lat/lon polygon or using a gridded data file such as the
NetCDF output of the Gen-Vx-Mask tool.</p>
<ul>
<li><p>An ASCII file containing a lat/lon polygon.
Latitude in degrees north and longitude in degrees east.
The first and last polygon points are connected.
For example, “MET_BASE/poly/EAST.poly” which consists of n points:
“poly_name lat1 lon1 lat2 lon2… latn lonn”</p>
<p>Several masking polygons used by NCEP are predefined in the
installed share/met/poly directory. Creating a new polygon is as
simple as creating a text file with a name for the polygon followed
by the lat/lon points which define its boundary. Adding a new masking
polygon requires no code changes and no recompiling. Internally, the
lat/lon polygon points are converted into x/y values in the grid. The
lat/lon values for the observation points are also converted into x/y
grid coordinates. The computations performed to check whether the
observation point falls within the polygon defined is done in x/y
grid space.</p>
</li>
<li><p>The NetCDF output of the gen_vx_mask tool.</p></li>
<li><p>Any gridded data file that MET can read may be used to define a
verification masking region. Users must specify a description of the
field to be used from the input file and, optionally, may specify a
threshold to be applied to that field. Once this threshold is
applied, any grid point where the resulting field is 0, the mask is
turned off. Any grid point where it is non-zero, the mask is turned
on.
For example,  “sample.grib {name = “TMP”; level = “Z2”;} &gt;273”</p></li>
</ul>
</li>
<li><p>The “sid” entry is an array of strings which define groups of
observation station ID’s over which to compute statistics. Each entry
in the array is either a filename of a comma-separated list.</p>
<ul class="simple">
<li><p>For a filename, the strings are whitespace-separated. The first
string is the mask “name” and the remaining strings are the station
ID’s to be used.</p></li>
<li><p>For a comma-separated list, optionally use a colon to specify a name.
For “MY_LIST:SID1,SID2”, name = MY_LIST and values = SID1 and SID2.</p></li>
<li><p>For a comma-separated list of length one with no name specified, the
mask “name” and value are both set to the single station ID string.
For “SID1”, name = SID1 and value = SID1.</p></li>
<li><p>For a comma-separated list of length greater than one with no name
specified, the name is set to MASK_SID and the values are the station
ID’s to be used.
For “SID1,SID2”, name = MASK_SID and values = SID1 and SID2.</p></li>
<li><p>The “name” of the station ID mask is written to the VX_MASK column
of the MET output files.</p></li>
</ul>
</li>
<li><p>The “llpnt” entry is either a single dictionary or an array of
dictionaries. Each dictionary contains three entries, the “name” for
the masking region, “lat_thresh”, and “lon_thresh”. The latitude and
longitude thresholds are applied directly to the point observation
latitude and longitude values. Only observations whose latitude and
longitude values meet this threshold criteria are used. A threshold set
to “NA” always evaluates to true.</p></li>
</ul>
<p>The masking logic for processing point observations in Point-Stat and
Ensemble-Stat fall into two cateogries. The “sid” and “llpnt” options apply
directly to the point observations. Only those observations for the specified
station id’s are included in the “sid” masks. Only those observations meeting
the latitude and longitude threshold criteria are included in the “llpnt”
masks.</p>
<p>The “grid” and “poly” mask options are applied to the grid points of the
verification domain. Each grid point is determined to be inside or outside
the masking region. When processing point observations, their latitude and
longitude values are rounded to the nearest grid point of the verification
domain. If the nearest grid point is inside the mask, that point observation
is included in the mask.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>mask = {
   grid    = [ &quot;FULL&quot; ];
   poly    = [ &quot;MET_BASE/poly/LMV.poly&quot;,
               &quot;MET_BASE/out/gen_vx_mask/CONUS_poly.nc&quot;,
               &quot;MET_BASE/sample_fcst/2005080700/wrfprs_ruc13_12.tm00_G212 \
               {name = \&quot;TMP\&quot;; level = \&quot;Z2\&quot;;} &gt;273&quot;
             ];
   sid     = [ &quot;CONUS.stations&quot; ];
   llpnt   = [ { name       = &quot;LAT30TO40&quot;;
                 lat_thresh = &gt;=30&amp;&amp;&lt;=40;
                 lon_thresh = NA; },
               { name       = &quot;BOX&quot;;
                 lat_thresh = &gt;=20&amp;&amp;&lt;=40;
                 lon_thresh = &gt;=-110&amp;&amp;&lt;=-90; } ];
}
</pre></div>
</div>
<p><strong>ci_alpha</strong></p>
<p>The “ci_alpha” entry is an array of floats specifying the values for alpha
to be used when computing confidence intervals. Values of alpha must be
between 0 and 1. The confidence interval computed is 1 minus the alpha
value. Therefore, an alpha value of 0.05 corresponds to a 95% confidence
interval.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>ci_alpha = [ 0.05, 0.10 ];
</pre></div>
</div>
<p><strong>boot</strong></p>
<p>The “boot” entry defines the parameters to be used in calculation of
bootstrap confidence intervals. The interval variable indicates what method
should be used for computing bootstrap confidence intervals:</p>
<ul>
<li><p>The “interval” entry specifies the confidence interval method:</p>
<ul class="simple">
<li><p>“BCA” for the BCa (bias-corrected percentile) interval method is
highly accurate but computationally intensive.</p></li>
<li><p>“PCTILE” uses the percentile method which is somewhat less accurate
but more efficient.</p></li>
</ul>
</li>
<li><p>The “rep_prop” entry specifies a proportion between 0 and 1 to define
the replicate sample size to be used when computing percentile
intervals. The replicate sample size is set to boot_rep_prop * n,
where n is the number of raw data points.</p>
<p>When computing bootstrap confidence intervals over n sets of matched
pairs, the size of the subsample, m, may be chosen less than or equal to
the size of the sample, n. This variable defines the size of m as a
proportion relative to the size of n. A value of 1 indicates that the
size of the subsample, m, should be equal to the size of the sample, n.</p>
</li>
<li><p>The “n_rep” entry defines the number of subsamples that should be taken
when computing bootstrap confidence intervals. This variable should be
set large enough so that when confidence intervals are computed multiple
times for the same set of data, the intervals do not change much.
Setting this variable to zero disables the computation of bootstrap
confidence intervals, which may be necessary to run MET in realtime or
near-realtime over large domains since bootstrapping is computationally
expensive. Setting this variable to 1000 indicates that bootstrap
confidence interval should be computed over 1000 subsamples of the
matched pairs.</p></li>
<li><p>The “rng” entry defines the random number generator to be used in the
computation of bootstrap confidence intervals. Subsamples are chosen at
random from the full set of matched pairs. The randomness is determined
by the random number generator specified. Users should refer to detailed
documentation of the
<a class="reference external" href="https://www.gnu.org/software/gsl/doc/html/rng.html">GNU Scientific Library</a>
for a listing of the random number generators available for use.</p></li>
<li><p>The “seed” entry may be set to a specific value to make the computation
of bootstrap confidence intervals fully repeatable. When left empty
the random number generator seed is chosen automatically which will lead
to slightly different bootstrap confidence intervals being computed each
time the data is run. Specifying a value here ensures that the bootstrap
confidence intervals will be reproducable over multiple runs on the same
computing platform.</p></li>
</ul>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>boot = {
   interval = PCTILE;
   rep_prop = 1.0;
   n_rep    = 0;
   rng      = &quot;mt19937&quot;;
   seed     = &quot;&quot;;
}
</pre></div>
</div>
<p><strong>interp</strong></p>
<p>The “interp” entry is a dictionary that specifies what interpolation or
smoothing (for the Grid-Stat tool) methods should be applied.
This dictionary may include the following entries:</p>
<ul>
<li><p>The “field” entry specifies to which field(s) the interpolation method
should be applied. This does not apply when doing point verification
with the Point-Stat or Ensemble-Stat tools:</p>
<ul class="simple">
<li><p>“FCST” to interpolate/smooth the forecast field.</p></li>
<li><p>“OBS” to interpolate/smooth the observation field.</p></li>
<li><p>“BOTH” to interpolate/smooth both the forecast and the observation.</p></li>
</ul>
</li>
<li><p>The “vld_thresh” entry specifies a number between 0 and 1. When
performing interpolation over some neighborhood of points the ratio of
the number of valid data points to the total number of points in the
neighborhood is computed. If that ratio is less than this threshold,
the matched pair is discarded. Setting this threshold to 1, which is the
default, requires that the entire neighborhood must contain valid data.
This variable will typically come into play only along the boundaries of
the verification region chosen.</p></li>
<li><p>The “shape” entry may be set to SQUARE or CIRCLE to specify the shape
of the smoothing area.</p></li>
<li><p>The “type” entry is an array of dictionaries, each specifying an
interpolation method. Interpolation is performed over a N by N box
centered on each point, where N is the width specified. Each of these
dictionaries must include:</p>
<ul>
<li><p>The “width” entry is an integer which specifies the size of the
interpolation area. The area is either a square or circle containing
the observation point. The width value specifies the width of the
square or diameter of the circle. A width value of 1 is interpreted
as the nearest neighbor model grid point to the observation point.
For squares, a width of 2 defines a 2 x 2 box of grid points around
the observation point (the 4 closest model grid points), while a width
of 3 defines a 3 x 3 box of grid points around the observation point,
and so on. For odd widths in grid-to-point comparisons
(i.e. Point-Stat), the interpolation area is centered on the model
grid point closest to the observation point. For grid-to-grid
comparisons (i.e. Grid-Stat), the width must be odd.</p></li>
<li><p>The “method” entry specifies the interpolation procedure to be
applied to the points in the box:</p>
<ul class="simple">
<li><p>MIN         for the minimum value</p></li>
<li><p>MAX         for the maximum value</p></li>
<li><p>MEDIAN      for the median value</p></li>
<li><p>UW_MEAN     for the unweighted average value</p></li>
<li><p>DW_MEAN     for the distance-weighted average value
where weight = distance^-2</p></li>
<li><p>LS_FIT      for a least-squares fit</p></li>
<li><p>BILIN       for bilinear interpolation (width = 2)</p></li>
<li><p>NEAREST     for the nearest grid point (width = 1)</p></li>
<li><p>BEST        for the value closest to the observation</p></li>
<li><p>UPPER_LEFT  for the upper left grid point (width = 1)</p></li>
<li><p>UPPER_RIGHT for the upper right grid point (width = 1)</p></li>
<li><p>LOWER_RIGHT for the lower right grid point (width = 1)</p></li>
<li><p>LOWER_LEFT  for the lower left grid point (width = 1)</p></li>
<li><p>GAUSSIAN    for the Gaussian kernel</p></li>
<li><p>MAXGAUSS    for the maximum value followed by a Gaussian smoother</p></li>
<li><p>GEOG_MATCH  for the nearest grid point where the land/sea mask
and geography criteria are satisfied.</p></li>
</ul>
<p>The BUDGET, FORCE, GAUSSIAN, and MAXGAUSS methods are not valid for
interpolating to point locations. For grid-to-grid comparisons, the
only valid smoothing methods are MIN, MAX, MEDIAN, UW_MEAN, and
GAUSSIAN, and MAXGAUSS.</p>
</li>
</ul>
</li>
</ul>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>interp = {
   field      = BOTH;
   vld_thresh = 1.0;
   shape      = SQUARE;

   type = [
      {
         method = UW_MEAN;
         width  = 1;
      }
   ];
}
</pre></div>
</div>
<p><strong>nbrhd</strong></p>
<p>The “nbrhd” entry is a dictionary that is very similar to the “interp”
entry. It specifies information for computing neighborhood statistics in
Grid-Stat. This dictionary may include the following entries:</p>
<ul class="simple">
<li><p>The “field” entry specifies to which field(s) the computation of
fractional coverage should be applied. Grid-Stat processes each
combination of categorical threshold and neighborhood width to
derive the fractional coverage fields from which neighborhood
statistics are calculated. Users who have computed fractional
coverage fields outside of MET can use this option to disable
these computations. Instead, the raw input values will be
used directly to compute neighborhood statistics:</p>
<ul>
<li><p>“BOTH” to compute fractional coverage for both the forecast
and the observation fields (default).</p></li>
<li><p>“FCST” to only process the forecast field.</p></li>
<li><p>“OBS”  to only process the observation field.</p></li>
<li><p>“NONE” to process neither field.</p></li>
</ul>
</li>
<li><p>The “vld_thresh” entry is described above.</p></li>
<li><p>The “shape” entry defines the shape of the neighborhood.
Valid values are “SQUARE” or “CIRCLE”</p></li>
<li><p>The “width” entry is as described above, and must be odd.</p></li>
<li><p>The “cov_thresh” entry is an array of thresholds to be used when
computing categorical statistics for the neighborhood fractional
coverage field.</p></li>
</ul>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>nbrhd = {
   field      = BOTH;
   vld_thresh = 1.0;
   shape      = SQUARE;
   width      = [ 1 ];
   cov_thresh = [ &gt;=0.5 ];
}
</pre></div>
</div>
<p><strong>fourier</strong></p>
<p>The “fourier” entry is a dictionary which specifies the application of the
Fourier decomposition method. It consists of two arrays of the same length
which define the beginning and ending wave numbers to be included. If the
arrays have length zero, no Fourier decomposition is applied. For each array
entry, the requested Fourier decomposition is applied to the forecast and
observation fields. The beginning and ending wave numbers are indicated in
the MET ASCII output files by the INTERP_MTHD column (e.g. WV1_0-3 for waves
0 to 3 or WV1_10 for only wave 10). This 1-dimensional Fourier decomposition
is computed along the Y-dimension only (i.e. the columns of data). It is only
defined when each grid point contains valid data. If either input field
contains missing data, no Fourier decomposition is computed.</p>
<p>The available wave numbers start at 0 (the mean across each row of data)
and end at (Nx+1)/2 (the finest level of detail), where Nx is the X-dimension
of the verification grid:</p>
<ul class="simple">
<li><p>The “wave_1d_beg” entry is an array of integers specifying the first
wave number to be included.</p></li>
<li><p>The “wave_1d_end” entry is an array of integers specifying the last
wave number to be included.</p></li>
</ul>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>fourier = {
   wave_1d_beg = [ 0, 4, 10 ];
   wave_1d_end = [ 3, 9, 20 ];
}
</pre></div>
</div>
<p><strong>gradient</strong></p>
<p>The “gradient” entry is a dictionary which specifies the number and size of
gradients to be computed. The “dx” and “dy” entries specify the size of the
gradients in grid units in the X and Y dimensions, respectively. dx and dy
are arrays of integers (positive or negative) which must have the same
length, and the GRAD output line type will be computed separately for each
entry. When computing gradients, the value at the (x, y) grid point is
replaced by the value at the (x+dx, y+dy) grid point minus the value at
(x, y).</p>
<p>This configuration option may be set separately in each “obs.field” entry.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>gradient = {
   dx = [ 1 ];
   dy = [ 1 ];
}
</pre></div>
</div>
<p><strong>distance_map</strong></p>
<p>The “distance_map” entry is a dictionary containing options related to the
distance map statistics in the DMAP output line type. The “baddeley_p” entry
is an integer specifying the exponent used in the Lp-norm when computing the
Baddeley Delta metric. The “baddeley_max_dist” entry is a floating point
number specifying the maximum allowable distance for each distance map. Any
distances larger than this number will be reset to this constant. A value of
NA indicates that no maximum distance value should be used. The “fom_alpha”
entry is a floating point number specifying the scaling constant to be used
when computing Pratt’s Figure of Merit. The “zhu_weight” specifies a value
between 0 and 1 to define the importance of the RMSE of the binary fields
(i.e. amount of overlap) versus the mean-error distance (MED). The default
value of 0.5 gives equal weighting.</p>
<p>This configuration option may be set separately in each “obs.field” entry.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>distance_map = {
   baddeley_p        = 2;
   baddeley_max_dist = NA;
   fom_alpha         = 0.1;
   zhu_weight        = 0.5;
}
</pre></div>
</div>
<p><strong>land_mask</strong></p>
<p>The “land_mask” dictionary defines the land/sea mask field which is used
when verifying at the surface. For point observations whose message type
appears in the “LANDSF” entry of the “message_type_group_map” setting,
only use forecast grid points where land = TRUE. For point observations
whose message type appears in the “WATERSF” entry of the
“message_type_group_map” setting, only use forecast grid points where
land = FALSE. The “flag” entry enables/disables this logic. If the
“file_name” entry is left empty, then the land/sea is assumed to exist in
the input forecast file. Otherwise, the specified file(s) are searched for
the data specified in the “field” entry. The “regrid” settings specify how
this field should be regridded to the verification domain. Lastly, the
“thresh” entry is the threshold which defines land (threshold is true) and
water (threshold is false).
land_mask.flag may be set separately in each “obs.field” entry.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>land_mask = {
   flag      = FALSE;
   file_name = [];
   field     = { name = &quot;LAND&quot;; level = &quot;L0&quot;; }
   regrid    = { method = NEAREST; width = 1; }
   thresh    = eq1;
}
</pre></div>
</div>
<p><strong>topo_mask</strong></p>
<p>The “topo_mask” dictionary defines the model topography field which is used
when verifying at the surface. This logic is applied to point observations
whose message type appears in the “SURFACE” entry of the
“message_type_group_map” setting. Only use point observations where the
topo - station elevation difference meets the “use_obs_thresh” threshold
entry. For the observations kept, when interpolating forecast data to the
observation location, only use forecast grid points where the topo - station
difference meets the “interp_fcst_thresh” threshold entry. The flag entry
enables/disables this logic. If the “file_name” is left empty, then the
topography data is assumed to exist in the input forecast file. Otherwise,
the specified file(s) are searched for the data specified in the “field”
entry. The “regrid” settings specify how this field should be regridded to
the verification domain.</p>
<p>topo_mask.flag may be set separately in each “obs.field” entry.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>topo_mask = {
   flag               = FALSE;
   file_name          = [];
   field              = { name = &quot;TOPO&quot;; level = &quot;L0&quot;; }
   regrid             = { method = BILIN; width = 2; }
   use_obs_thresh     = ge-100&amp;&amp;le100;
   interp_fcst_thresh = ge-50&amp;&amp;le50;
}
</pre></div>
</div>
<p><strong>hira</strong></p>
<p>The “hira” entry is a dictionary that is very similar to the “interp” and
“nbrhd” entries. It specifies information for applying the High Resolution
Assessment (HiRA) verification logic in Point-Stat. HiRA is analogous to
neighborhood verification but for point observations. The HiRA logic
interprets the forecast values surrounding each point observation as an
ensemble forecast. These ensemble values are processed in two ways. First,
the ensemble continuous statistics (ECNT) and ranked probability score (RPS)
line types are computed directly from the ensemble values. Second, for each
categorical threshold specified, a fractional coverage value is computed as
the ratio of the nearby forecast values that meet the threshold criteria.
Point-Stat evaluates those fractional coverage values as if they were a
probability forecast. When applying HiRA, users should enable the matched
pair (MPR), probabilistic (PCT, PSTD, PJC, or PRC), or ensemble statistics
(ECNT or PRS) line types in the output_flag dictionary. The number of
probabilistic HiRA output lines is determined by the number of categorical
forecast thresholds and HiRA neighborhood widths chosen.
This dictionary may include the following entries:</p>
<ul class="simple">
<li><p>The “flag” entry is a boolean which toggles “hira”
on (TRUE) and off (FALSE).</p></li>
<li><p>The “width” entry specifies the neighborhood size. Since HiRA applies
to point observations, the width may be even or odd.</p></li>
<li><p>The “vld_thresh” entry is as described above.</p></li>
<li><p>The “cov_thresh” entry is an array of probabilistic thresholds used to
populate the Nx2 probabilistic contingency table written to the PCT
output line and used for computing probabilistic statistics.</p></li>
<li><p>The “shape” entry defines the shape of the neighborhood.
Valid values are “SQUARE” or “CIRCLE”</p></li>
<li><p>The “prob_cat_thresh” entry defines the thresholds which define ensemble
probabilities from which to compute the ranked probability score output.
If left empty but climatology data is provided, the climo_cdf thresholds
will be used instead. If left empty but no climatology data is provided,
the obs.cat_thresh thresholds will be used instead.</p></li>
</ul>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>hira = {
    flag            = FALSE;
   width           = [ 2, 3, 4, 5 ];
   vld_thresh      = 1.0;
   cov_thresh      = [ ==0.25 ];
   shape           = SQUARE;
   prob_cat_thresh = [];
}
</pre></div>
</div>
<p><strong>output_flag</strong></p>
<p>The “output_flag” entry is a dictionary that specifies what verification
methods should be applied to the input data. Options exist for each
output line type from the MET tools. Each line type may be set to one of:</p>
<ul class="simple">
<li><p>“NONE” to skip the corresponding verification method</p></li>
<li><p>“STAT” to write the verification output only to the “.stat” output file</p></li>
<li><p>“BOTH” to write to the “.stat” output file as well the optional
“_type.txt” file, a more readable ASCII file sorted by line type.</p></li>
</ul>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>output_flag = {
   fho    = NONE;  Forecast, Hit, Observation Rates
   ctc    = NONE;  Contingency Table Counts
   cts    = NONE;  Contingency Table Statistics
   mctc   = NONE;  Multi-category Contingency Table Counts
   mcts   = NONE;  Multi-category Contingency Table Statistics
   cnt    = NONE;  Continuous Statistics
   sl1l2  = NONE;  Scalar L1L2 Partial Sums
   sal1l2 = NONE;  Scalar Anomaly L1L2 Partial Sums when climatological data
                   is supplied
   vl1l2  = NONE;  Vector L1L2 Partial Sums
   val1l2 = NONE;  Vector Anomaly L1L2 Partial Sums when climatological data
                   is supplied
   pct    = NONE;  Contingency Table Counts for Probabilistic Forecasts
   pstd   = NONE;  Contingency Table Statistics for Probabilistic Forecasts
                   with Dichotomous outcomes
   pjc    = NONE;  Joint and Conditional Factorization for Probabilistic
                   Forecasts
   prc    = NONE;  Receiver Operating Characteristic for Probabilistic
                   Forecasts
   eclv   = NONE;  Economic Cost/Loss Value derived from CTC and PCT lines
   mpr    = NONE;  Matched Pair Data
   nbrctc = NONE;  Neighborhood Contingency Table Counts
   nbrcts = NONE;  Neighborhood Contingency Table Statistics
   nbrcnt = NONE;  Neighborhood Continuous Statistics
   isc    = NONE;  Intensity-Scale
   ecnt   = NONE;  Ensemble Continuous Statistics
   rps    = NONE;  Ranked Probability Score Statistics
   rhist  = NONE;  Rank Histogram
   phist  = NONE;  Probability Integral Transform Histogram
   orank  = NONE;  Observation Rank
   ssvar  = NONE;  Spread Skill Variance
   grad   = NONE;  Gradient statistics (S1 score)
}
</pre></div>
</div>
<p><strong>nc_pairs_flag</strong></p>
<p>The “nc_pairs_flag” can be set either to a boolean value or a dictionary
in either Grid-Stat, Wavelet-Stat or MODE. The dictionary (with slightly
different entries for the various tools … see the default config files)
has individual boolean settings turning on or off the writing out of the
various fields in the netcdf output file for the tool. Setting all
dictionary entries to false means the netcdf file will not be generated.</p>
<p>“nc_pairs_flag” can also be set to a boolean value. In this case, a value
of true means to just accept the default settings (which will turn on
the output of all the different fields). A value of false means no
netcdf output will be generated.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>nc_pairs_flag = {
   latlon       = TRUE;
   raw          = TRUE;
   diff         = TRUE;
   climo        = TRUE;
   climo_cdp    = FALSE;
   weight       = FALSE;
   nbrhd        = FALSE;
   fourier      = FALSE;
   gradient     = FALSE;
   distance_map = FLASE;
   apply_mask   = TRUE;
}
</pre></div>
</div>
<p><strong>nc_pairs_var_name</strong></p>
<p>The “nc_pairs_var_name” entry specifies a string for each verification task
in Grid-Stat. This string is parsed from each “obs.field” dictionary entry
and is used to construct variable names for the NetCDF matched pairs output
file. The default value of an empty string indicates that the “name” and
“level” strings of the input data should be used.  If the input data “level”
string changes for each run of Grid-Stat, using this option to define a
constant string may make downstream processing more convenient.</p>
<p>For example:</p>
<div class="line-block">
<div class="line">nc_pairs_var_name = “TMP”;</div>
<div class="line"><br /></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>nc_pairs_var_name = &quot;&quot;;
</pre></div>
</div>
<p><strong>nc_pairs_var_suffix</strong></p>
<p>The “nc_pairs_var_suffix” entry is similar to the “nc_pairs_var_name” entry
described above.  It is also parsed from each “obs.field” dictionary entry.
However, it defines a suffix to be appended to the output variable name.
This enables the output variable names to be made unique. For example, when
verifying height for multiple level types but all with the same level value,
use this option to customize the output variable names.</p>
<p>For example:</p>
<div class="line-block">
<div class="line">nc_pairs_var_suffix = “TROPO”; (for the tropopause height)</div>
<div class="line">nc_pairs_var_suffix = “FREEZING”; (for the freezing level height)</div>
<div class="line"><br /></div>
</div>
<p>NOTE: This option was previously named “nc_pairs_var_str”, which is
now deprecated.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>nc_pairs_var_suffix = &quot;&quot;;
</pre></div>
</div>
<p><strong>ps_plot_flag</strong></p>
<p>The “ps_plot_flag” entry is a boolean value for Wavelet-Stat and MODE
indicating whether a PostScript plot should be generated summarizing
the verification.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>ps_plot_flag = TRUE;
</pre></div>
</div>
<p><strong>grid_weight_flag</strong></p>
<p>The “grid_weight_flag” specifies how grid weighting should be applied
during the computation of continuous statistics and partial sums. It is
meant to account for grid box area distortion and is often applied to global
Lat/Lon grids. It is only applied for grid-to-grid verification in Grid-Stat
and Ensemble-Stat and is not applied for grid-to-point verification.
Three grid weighting options are currently supported:</p>
<ul class="simple">
<li><p>“NONE” to disable grid weighting using a constant weight (default).</p></li>
<li><p>“COS_LAT” to define the weight as the cosine of the grid point latitude.
This an approximation for grid box area used by NCEP and WMO.</p></li>
<li><p>“AREA” to define the weight as the true area of the grid box (km^2).</p></li>
</ul>
<p>The weights are ultimately computed as the weight at each grid point divided
by the sum of the weights for the current masking region.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>grid_weight_flag = NONE;
</pre></div>
</div>
<p><strong>rank_corr_flag</strong></p>
<p>The “rank_corr_flag” entry is a boolean to indicate whether Kendall’s Tau
and Spearman’s Rank Correlation Coefficients (in the CNT line type) should
be computed. Computing them over large datasets is computationally
intensive and slows down the runtime significantly.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>rank_corr_flag = FALSE;
</pre></div>
</div>
<p><strong>duplicate_flag</strong></p>
<p>The “duplicate_flag” entry specifies how to handle duplicate point
observations in Point-Stat and Ensemble-Stat:</p>
<ul class="simple">
<li><p>“NONE” to use all point observations (legacy behavior)</p></li>
<li><p>“UNIQUE” only use a single observation if two or more observations
match. Matching observations are determined if they contain identical
latitude, longitude, level, elevation, and time information.
They may contain different observation values or station IDs</p></li>
</ul>
<p>The reporting mechanism for this feature can be activated by specifying
a verbosity level of three or higher. The report will show information
about where duplicates were detected and which observations were used
in those cases.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>duplicate_flag = NONE;
</pre></div>
</div>
<p><strong>obs_summary</strong></p>
<p>The “obs_summary” entry specifies how to compute statistics on
observations that appear at a single location (lat,lon,level,elev)
in Point-Stat and Ensemble-Stat. Eight techniques are
currently supported:</p>
<ul class="simple">
<li><p>“NONE” to use all point observations (legacy behavior)</p></li>
<li><p>“NEAREST” use only the observation that has the valid
time closest to the forecast valid time</p></li>
<li><p>“MIN” use only the observation that has the lowest value</p></li>
<li><p>“MAX” use only the observation that has the highest value</p></li>
<li><p>“UW_MEAN” compute an unweighted mean of the observations</p></li>
<li><p>“DW_MEAN” compute a weighted mean of the observations based
on the time of the observation</p></li>
<li><p>“MEDIAN” use the median observation</p></li>
<li><p>“PERC” use the Nth percentile observation where N = obs_perc_value</p></li>
</ul>
<p>The reporting mechanism for this feature can be activated by specifying
a verbosity level of three or higher. The report will show information
about where duplicates were detected and which observations were used
in those cases.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>obs_summary = NONE;
</pre></div>
</div>
<p><strong>obs_perc_value</strong></p>
<p>Percentile value to use when obs_summary = PERC</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>obs_perc_value = 50;
</pre></div>
</div>
<p><strong>obs_quality</strong></p>
<p>The “obs_quality” entry specifies the quality flag values that are to be
retained and used for verification. An empty list signifies that all
point observations should be used, regardless of their quality flag value.
The quality flag values will vary depending on the original source of the
observations. The quality flag values to retain should be specified as
an array of strings, even if the values themselves are numeric.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>obs_quality = [ &quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;9&quot; ];
</pre></div>
</div>
<p><strong>met_data_dir</strong></p>
<p>The “met_data_dir” entry specifies the location of the internal MET data
sub-directory which contains data files used when generating plots. It
should be set to the installed share/met directory so the MET tools can
locate the static data files they need at run time.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>met_data_dir = &quot;MET_BASE&quot;;
</pre></div>
</div>
<p><strong>fcst_raw_plot, obs_raw_plot, wvlt_plot, object_plot</strong></p>
<p>The “fcst_raw_plot” entry is a dictionary used by Wavelet-Stat and MODE
containing colortable plotting information for the plotting of the raw
forecast field:</p>
<ul class="simple">
<li><p>The “color_table” entry specifies the location and name of the
colortable file to be used.</p></li>
<li><p>The “plot_min” and “plot_max” entries specify the range of data values.
If they are both set to 0, the MET tools will automatically rescale
the colortable to the range of values present in the data. If they
are not both set to 0, the MET tools will rescale the colortable using
their values.</p></li>
</ul>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>fcst_raw_plot = {
   color_table = &quot;MET_BASE/colortables/met_default.ctable&quot;;
   plot_min = 0.0;
   plot_max = 0.0;
}
</pre></div>
</div>
<p>The “obs_raw_plot”, “wvlt_plot”, and “object_plot” entries are dictionaries
similar to the “fcst_raw_plot” described above.</p>
<p><strong>tmp_dir</strong></p>
<p>The “tmp_dir” entry is a string specifying the location where temporary
files should be written.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>tmp_dir = &quot;/tmp&quot;;
</pre></div>
</div>
<p><strong>output_prefix</strong></p>
<p>The “output_prefix” entry specifies a string to be included in the output
file name. The MET statistics tools construct output file names that
include the tool name and timing information. You can use this setting
to modify the output file name and avoid naming conflicts for multiple runs
of the same tool.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>output_prefix  = &quot;&quot;;
</pre></div>
</div>
<p><strong>version</strong></p>
<p>The “version” entry specifies the version number of the configuration file.
The configuration file version number should match the version number of
the MET code being run. This value should generally not be modified.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>version = &quot;V6.0&quot;;
</pre></div>
</div>
<p><strong>time_summary</strong></p>
<p>This feature was implemented to allow additional processing of observations
with high temporal resolution. The “flag” entry toggles the “time_summary”
on (TRUE) and off (FALSE). Obs may be summarized across the user specified
time period defined by the “beg” and “end” entries. The “step” entry defines
the time between intervals in seconds. The “width” entry specifies the
summary interval in seconds. It may either be set as an integer number of
seconds for a centered time interval or a dictionary with beginning and
ending time offsets in seconds.</p>
<p>For example:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>beg = &quot;00&quot;;
end = &quot;235959&quot;;
step = 300;
width = 600;
width = { beg = -300; end = 300; }
</pre></div>
</div>
<p>This example does a 10-minute time summary every 5 minutes throughout the
day. The first interval will be from 23:55:00 the previous day through
00:04:59 of the current day. The second interval will be from 0:00:00
through 00:09:59. And so on.</p>
<p>The two “width” settings listed above are equivalent. Both define a centered
10-minute time interval. Use the “beg” and “end” entries to define
uncentered time intervals. The following example requests observations for
one hour prior:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>width = { beg = -3600; end = 0; }
</pre></div>
</div>
<p>The summaries will only be calculated for the specified GRIB codes.
The supported summaries are “min” (minimum), “max” (maximum), “range”,
“mean”, “stdev” (standard deviation), “median” and “p##” (percentile, with
the desired percentile value specified in place of ##).</p>
<p>The “vld_freq” and “vld_thresh” options may be used to require that a certain
ratio of observations must be present and contain valid data within the time
window in order for a summary value to be computed. The “vld_freq” entry
defines the expected observation frequency in seconds. For example, when
summarizing 1-minute data (vld_freq = 60) over a 30 minute time window,
setting “vld_thresh = 0.5” requires that at least 15 of the 30 expected
observations be present and valid for a summary value to be written. The
default “vld_thresh = 0.0” setting will skip over this logic.</p>
<p>The variable names are saved to NetCDF file if they are given instead of
grib_codes which are not available for non GRIB input. The “obs_var” option
was added and works like “grib_code” option (string value VS. int value).
They are inclusive (union). All variables are included if both options
are empty. Note: grib_code 11 is equivalent to obs_var “TMP”.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>time_summary = {
  flag = FALSE;
  beg = &quot;000000&quot;;
  end = &quot;235959&quot;;
  step = 300;
  width = 600;
  width = { beg = -300; end = 300; }
  grib_code = [ 11, 204, 211 ];
  obs_var   = [];
  type = [ &quot;min&quot;, &quot;max&quot;, &quot;range&quot;, &quot;mean&quot;, &quot;stdev&quot;, &quot;median&quot;, &quot;p80&quot; ];
  vld_freq = 0;
  vld_thresh = 0.0;
}
</pre></div>
</div>
</div>
<div class="section" id="settings-specific-to-individual-tools">
<h3><span class="section-number">26.1.2. </span>Settings specific to individual tools<a class="headerlink" href="#settings-specific-to-individual-tools" title="Permalink to this headline">¶</a></h3>
<div class="section" id="ensemblestatconfig-default">
<h4><span class="section-number">26.1.2.1. </span>EnsembleStatConfig_default<a class="headerlink" href="#ensemblestatconfig-default" title="Permalink to this headline">¶</a></h4>
<p><strong>ens</strong></p>
<p>The “ens” entry is a dictionary that specifies the fields for which ensemble
products should be generated. This is very similar to the “fcst” and “obs”
entries. This dictionary may include the following entries:</p>
<ul class="simple">
<li><p>The “censor_thresh” and “censor_val” entries are described above.</p></li>
<li><p>The “ens_thresh” entry specifies a proportion between 0 and 1 to define
the required ratio of valid input ensemble member files. If the ratio
of valid input ensemble files to expected ones is too low, the tool
will error out.</p></li>
<li><p>The “vld_thresh” entry specifies a proportion between 0 and 1 to
define the required ratio of valid data points. When computing
ensemble products, if the ratio of valid data values is too low, the
ensemble product will be set to bad data for that point.</p></li>
<li><p>The “field” entry is as described above. However, in this case, the
cat_thresh entry is used for calculating probabilities of exceeding
the given threshold. In the default shown below, the probability of
accumulated precipitation &gt; 0.0 mm and &gt; 5.0 mm will be calculated
from the member accumulated precipitation fields and stored as an
ensemble field.</p></li>
</ul>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>ens = {
   censor_thresh = [];
   censor_val    = [];
   ens_thresh    = 1.0;
   vld_thresh    = 1.0;

   field = [
      {
         name       = &quot;APCP&quot;;
         level      = &quot;A03&quot;;
         cat_thresh = [ &gt;0.0, &gt;=5.0 ];
      }
   ];
}
</pre></div>
</div>
<p><strong>nbrhd_prob</strong></p>
<p>The nbrhd_prob dictionary defines the neighborhoods used to compute NEP
and NMEP output. The neighborhood shape is a SQUARE or CIRCLE centered on
the current point, and the width array specifies the width of the square or
diameter of the circle as an odd integer. The vld_thresh entry is a number
between 0 and 1 specifying the required ratio of valid data in the
neighborhood for an output value to be computed.</p>
<p>If ensemble_flag.nep is set to TRUE, NEP output is created for each
combination of the categorical threshold (cat_thresh) and neighborhood width
specified.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>nbrhd_prob = {
   width      = [ 5 ];
   shape      = CIRCLE;
   vld_thresh = 0.0;
}
</pre></div>
</div>
<p><strong>nmep_smooth</strong></p>
<p>Similar to the interp dictionary, the nmep_smooth dictionary includes a type
array of dictionaries to define one or more methods for smoothing the NMEP
data. Setting the interpolation method to nearest neighbor (NEAREST)
effectively disables this smoothing step.</p>
<p>If ensemble_flag.nmep is set to TRUE, NMEP output is created for each
combination of the categorical threshold (cat_thresh), neighborhood width
(nbrhd_prob.width), and smoothing method (nmep_smooth.type) specified.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>nmep_smooth = {
   vld_thresh      = 0.0;
   shape           = CIRCLE;
   gaussian_dx     = 81.27;
   gaussian_radius = 120;
   type = [
      {
         method = GAUSSIAN;
         width  = 1;
      }
   ];
}
</pre></div>
</div>
<p><strong>fcst, obs</strong></p>
<p>The fcst and obs entries define the fields for which Ensemble-Stat should
compute rank histograms, probability integral transform histograms,
spread-skill variance, relative position histograms, economic value, and
other statistics.</p>
<p>The “ens_ssvar_bin_size” entry sets the width of the variance bins. Smaller
bin sizes provide the user with more flexibility in how data are binned
during analysis. The actual variance of the ensemble data will determine the
number of bins written to the SSVAR output lines.</p>
<p>The “ens_phist_bin_size” is set to a value between 0 and 1. The number of
bins for the probability integral transform histogram in the PHIST line type
is defined as the ceiling of 1.0 / ens_phist_bin_size. For example, a bin
size of 0.05 results in 20 PHIST bins.</p>
<p>The “prob_cat_thresh” entry is an array of thresholds to be applied in the
computation of the ranked probability score.  If left empty, but climatology
data is provided, the climo_cdf thresholds will be used instead.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>fcst = {
   message_type       = [ &quot;ADPUPA&quot; ];
   ens_ssvar_bin_size = 1;
   ens_phist_bin_size = 0.05;
   prob_cat_thresh    = [];

   field = [
      {
         name  = &quot;APCP&quot;;
         level = [ &quot;A03&quot; ];
      }
   ];
}
</pre></div>
</div>
<p><strong>nc_var_str</strong></p>
<p>The “nc_var_str” entry specifies a string for each ensemble field and
verification task in Ensemble-Stat. This string is parsed from each
“ens.field” and “obs.field” dictionary entry and is used to customize
the variable names written to the NetCDF output file. The default is an
empty string, meaning that no customization is applied to the output variable
names. When the Ensemble-Stat config file contains two fields with the same
name and level value, this entry is used to make the resulting variable names
unique.
e.g. nc_var_str = “MIN”;</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>nc_var_str = &quot;&quot;;
</pre></div>
</div>
<p><strong>obs_thresh</strong></p>
<p>The “obs_thresh” entry is an array of thresholds for filtering observation
values prior to applying ensemble verification logic. The default setting
of NA means that no observations should be filtered out. Verification output
will be computed separately for each threshold specified. This option may be
set separately for each obs.field entry.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>obs_thresh = [ NA ];
</pre></div>
</div>
<p><strong>skip_const</strong></p>
<p>Setting “skip_const” to true tells Ensemble-Stat to exclude pairs where all
the ensemble members and the observation have a constant value. For example,
exclude points with zero precipitation amounts from all output line types.
This option may be set separately for each obs.field entry. When set to
false, constant points are included and the observation rank is chosen at
random.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>skip_const = FALSE;
</pre></div>
</div>
<p><strong>obs_error</strong></p>
<p>Observation error options</p>
<p>Set dist_type to NONE to use the observation error table instead.
May be set separately in each “obs.field” entry.
The obs_error dictionary controls how observation error information should be
handled. Observation error information can either be specified directly in
the configuration file or by parsing information from an external table file.
By default, the MET_BASE/data/table_files/obs_error_table.txt file is read
but this may be overridden by setting the $MET_OBS_ERROR_TABLE environment
variable at runtime.</p>
<p>The flag entry toggles the observation error logic on (TRUE) and off (FALSE).
When flag is TRUE, random observation error perturbations are applied to the
ensemble member values. No perturbation is applied to the observation values
but the bias scale and offset values, if specified, are applied.</p>
<p>The dist_type entry may be set to NONE, NORMAL, EXPONENTIAL, CHISQUARED,
GAMMA, UNIFORM, or BETA. The default value of NONE indicates that the
observation error table file should be used rather than the configuration
file settings.</p>
<p>The dist_parm entry is an array of length 1 or 2 specifying the parameters
for the distribution selected in dist_type. The NORMAL, EXPONENTIAL, and
CHISQUARED distributions are defined by a single parameter. The GAMMA,
UNIFORM, and BETA distributions are defined by two parameters. See the
<a class="reference external" href="https://www.gnu.org/software/gsl/manual">GNU Scientific Library Reference Manual</a>
for more information on these distributions.</p>
<p>The inst_bias_scale and inst_bias_offset entries specify bias scale and
offset values that should be applied to observation values prior to
perturbing them. These entries enable bias-correction on the fly.</p>
<p>Defining the observation error information in the configuration file is
convenient but limited. If defined this way, the random perturbations for all
points in the current verification task are drawn from the same distribution.
Specifying an observation error table file instead (by setting dist_type =
NONE;) provides much finer control, enabling the user to define observation
error distribution information and bias-correction logic separately for each
observation variable name, message type, PREPBUFR report type, input report
type, instrument type, station ID, range of heights, range of pressure
levels, and range of values.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>obs_error = {
   flag             = FALSE;   TRUE or FALSE
   dist_type        = NONE;    Distribution type
   dist_parm        = [];      Distribution parameters
   inst_bias_scale  = 1.0;     Instrument bias scale adjustment
   inst_bias_offset = 0.0;     Instrument bias offset adjustment
   min              = NA;      Valid range of data
   max              = NA;
}
</pre></div>
</div>
<p><strong>ensemble_flag</strong></p>
<p>The “ensemble_flag” entry is a dictionary of boolean value indicating
which ensemble products should be generated:</p>
<ul class="simple">
<li><p>“mean” for the simple ensemble mean</p></li>
<li><p>“stdev” for the ensemble standard deviation</p></li>
<li><p>“minus” for the mean minus one standard deviation</p></li>
<li><p>“plus” for the mean plus one standard deviation</p></li>
<li><p>“min” for the ensemble minimum</p></li>
<li><p>“max” for the ensemble maximum</p></li>
<li><p>“range” for the range of ensemble values</p></li>
<li><p>“vld_count” for the number of valid ensemble members</p></li>
<li><p>“frequency” for the ensemble relative frequency meeting a threshold</p></li>
<li><p>“nep” for the neighborhood ensemble probability</p></li>
<li><p>“nmep” for the neighborhood maximum ensemble probability</p></li>
<li><p>“rank” to write the rank for the gridded observation field to separate
NetCDF output file.</p></li>
<li><p>“weight” to write the grid weights specified in grid_weight_flag to the
rank NetCDF output file.</p></li>
</ul>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>ensemble_flag = {
   mean      = TRUE;
   stdev     = TRUE;
   minus     = TRUE;
   plus      = TRUE;
   min       = TRUE;
   max       = TRUE;
   range     = TRUE;
   vld_count = TRUE;
   frequency = TRUE;
   nep       = FALSE;
   nmep      = FALSE;
   rank      = TRUE;
   weight    = FALSE;
}
</pre></div>
</div>
<p><strong>rng</strong></p>
<p>See: <a class="reference external" href="https://www.gnu.org/software/gsl/doc/html/rng.html#performance">Random Number Generator Performance</a>
used for random assignment of ranks when they are tied.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>rng = {
   type = &quot;mt19937&quot;;
   seed = &quot;&quot;;
}
</pre></div>
</div>
</div>
<div class="section" id="modeanalysisconfig-default">
<h4><span class="section-number">26.1.2.2. </span>MODEAnalysisConfig_default<a class="headerlink" href="#modeanalysisconfig-default" title="Permalink to this headline">¶</a></h4>
<p>MODE line options are used to create filters that determine which MODE output
lines are read in and processed. The MODE line options are numerous. They
fall into seven categories: toggles, multiple set string options, multiple
set integer options, integer max/min options, date/time max/min options,
floating-point max/min options, and miscellaneous options. <strong>In order to be
applied, the options must be uncommented (i.e. remove  the “//” marks) before
running.</strong> These options are described in subsequent sections. Please note
that this configuration file is processed differently than the other config
files.</p>
<p>Toggles: The MODE line options described in this section are shown in pairs.
These toggles represent parameters that can have only one (or none) of two
values. Any of these toggles may be left unspecified. However, if neither
option for toggle is indicated, the analysis will produce results that
combine data from both toggles. This may produce unintended results.</p>
<p>This toggle indicates whether forecast or observed lines should be used for
analysis.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>fcst      = FALSE;
obs       = FALSE;
</pre></div>
</div>
<p>This toggle indicates whether single object or object pair lines should be
used.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>single    = FALSE;
pair      = FALSE;
</pre></div>
</div>
<p>This toggle indicates whether simple object or object cluster object lines
should be used.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>simple    = FALSE;
cluster   = FALSE;
</pre></div>
</div>
<p>This toggle indicates whether matched or unmatched object lines should be
used.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>matched   = FALSE;
unmatched = FALSE;
</pre></div>
</div>
<p>Multiple-set string options: The following options set various string
attributes. They can be set multiple times on the command line but must be
separated by spaces. Each of these options must be indicated as a string.
String values that include spaces may be used by enclosing the string in
quotation marks.</p>
<p>This options specifies which model to use</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>// model    = [];
</pre></div>
</div>
<p>These two options specify thresholds for forecast and observations objects to
be used in the analysis, respectively.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>// fcst_thr = [];
// obs_thr  = [];
</pre></div>
</div>
<p>These options indicate the names of variables to be used in the analysis for
forecast and observed fields.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>// fcst_var = [];
// obs_var = [];
</pre></div>
</div>
<p>These options indicate vertical levels for forecast and observed fields to be
used in the analysis.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>// fcst_lev = [];
// obs_lev = [];
</pre></div>
</div>
<p>Multiple-set integer options: The following options set various integer
attributes. Each of the following options may only be indicated as an
integer.</p>
<p>These options are integers of the form HH[MMSS] specifying the lead_time.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>// fcst_lead       = [];
//obs_lead       = [];
</pre></div>
</div>
<p>These options are integers of the form HH[MMSS] specifying the valid hour.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>// fcst_valid_hour = [];
// obs_valid_hour = [];
</pre></div>
</div>
<p>These options are integers of the form HH[MMSS] specifying the model
initialization hour.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>// fcst_init_hour  = [];
// obs_init_hour  = [];
</pre></div>
</div>
<p>These options are integers of the form HHMMSS specifying the accumulation
time.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>// fcst_accum      = [];
// obs_accum      = [];
</pre></div>
</div>
<p>These options indicate the convolution radius used for forecast of observed
objects, respectively.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>// fcst_rad        = [];
// obs_rad        = [];
</pre></div>
</div>
<p>Integer max/min options: These options set limits on various integer
attributes. Leaving a maximum value unset means no upper limit is imposed on
the value of the attribute. The option works similarly for minimum values.</p>
<p>These options are used to indicate minimum/maximum values for the area
attribute to be used in the analysis.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>// area_min              = 0;
// area_max              = 0;
</pre></div>
</div>
<p>These options are used to indicate minimum/maximum values accepted for the
area thresh. The area thresh is the area of the raw field inside the object
that meets the threshold criteria.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>// area_thresh_min       = 0;
// area_thresh_max       = 0;
</pre></div>
</div>
<p>These options refer to the minimum/maximum values accepted for the
intersection area attribute.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>// intersection_area_min = 0;
// intersection_area_max = 0;
</pre></div>
</div>
<p>These options refer to the minimum/maximum union area values accepted for
analysis.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>// union_area_min        = 0;
// union_area_max        = 0;
</pre></div>
</div>
<p>These options refer to the minimum/maximum values for symmetric difference
for objects to be used in the analysis.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>// symmetric_diff_min    = 0;
// symmetric_diff_max    = 0;
</pre></div>
</div>
<p>Date/time max/min options: These options set limits on various date/time
attributes. The values can be specified in one of three ways:  First, the
options may be indicated by a string of the form YYYMMDD_HHMMSS. This
specifies a complete calendar date and time. Second, they may be indicated
by a string of the form YYYYMMMDD_HH. Here, the minutes and seconds are
assumed to be zero. The third way of indicating date/time attributes is by a
string of the form YYYMMDD. Here, hours, minutes, and seconds are assumed to
be zero.</p>
<p>These options indicate minimum/maximum values for the forecast valid time.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>// fcst_valid_min = &quot;&quot;;
// fcst_valid_max = &quot;&quot;;
</pre></div>
</div>
<p>These options indicate minimum/maximum values for the observation valid time.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>// obs_valid_min  = &quot;&quot;;
// obs_valid_max  = &quot;&quot;;
</pre></div>
</div>
<p>These options indicate minimum/maximum values for the forecast initialization
time.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>// fcst_init_min  = &quot;&quot;;
// fcst_init_max  = &quot;&quot;;
</pre></div>
</div>
<p>These options indicate minimum/maximum values for the observation
initialization time.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>// obs_init_min   = &quot;&quot;;
// obs_init_max   = &quot;&quot;;
</pre></div>
</div>
<p>Floating-point max/min options: Setting limits on various floating-point
attributes. One may specify these as integers (i.e., without a decimal
point), if desired. The following pairs of options indicate minimum and
maximum values for each MODE attribute that can be described as a floating-
point number. Please refer to “The MODE Tool” section on attributes in the
MET User’s Guide for a description of these attributes.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>// centroid_x_min                 = 0.0;
// centroid_x_max                 = 0.0;

// centroid_y_min                 = 0.0;
// centroid_y_max                 = 0.0;

// centroid_lat_min               = 0.0;
// centroid_lat_max               = 0.0;

// centroid_lon_min               = 0.0;
// centroid_lon_max               = 0.0;

// axis_ang_min                   = 0.0;
// axis_ang_max                   = 0.0;

// length_min                     = 0.0;
// length_max                     = 0.0;

// width_min                      = 0.0;
// width_max                      = 0.0;

// aspect_ratio_min               = 0.0;
// aspect_ratio_max               = 0.0;

// curvature_min                  = 0.0;
// curvature_max                  = 0.0;

// curvature_x_min                = 0.0;
// curvature_x_max                = 0.0;

// curvature_y_min                = 0.0;
// curvature_y_max                = 0.0;

// complexity_min                 = 0.0;
// complexity_max                 = 0.0;

// intensity_10_min               = 0.0;
// intensity_10_max               = 0.0;

// intensity_25_min               = 0.0;
// intensity_25_max               = 0.0;

// intensity_50_min               = 0.0;
// intensity_50_max               = 0.0;

// intensity_75_min               = 0.0;
// intensity_75_max               = 0.0;

// intensity_90_min               = 0.0;
// intensity_90_max               = 0.0;

// intensity_user_min             = 0.0;
// intensity_user_max             = 0.0;

// intensity_sum_min              = 0.0;
// intensity_sum_max              = 0.0;

// centroid_dist_min              = 0.0;
// centroid_dist_max              = 0.0;

// boundary_dist_min              = 0.0;
// boundary_dist_max              = 0.0;

// convex_hull_dist_min           = 0.0;
// convex_hull_dist_max           = 0.0;

// angle_diff_min                 = 0.0;
// angle_diff_max                 = 0.0;

// area_ratio_min                 = 0.0;
// area_ratio_max                 = 0.0;

// intersection_over_area_min     = 0.0;
// intersection_over_area_max     = 0.0;

// complexity_ratio_min           = 0.0;
// complexity_ratio_max           = 0.0;

// percentile_intensity_ratio_min = 0.0;
// percentile_intensity_ratio_max = 0.0;

// interest_min                   = 0.0;
// interest_max                   = 0.0;
</pre></div>
</div>
</div>
<div class="section" id="modeconfig-default">
<h4><span class="section-number">26.1.2.3. </span>MODEConfig_default<a class="headerlink" href="#modeconfig-default" title="Permalink to this headline">¶</a></h4>
<p><strong>quilt</strong></p>
<p>The “quilt” entry is a boolean to indicate whether all permutations of
convolution radii and thresholds should be run. If set to false, the number
of forecast and observation convolution radii and thresholds must all match.
One configuration of MODE will be run for each group of settings in those
lists. If set to true, the number of forecast and observation convolution
radii must match and the number of forecast and observation convolution
thresholds must match. For N radii and M thresholds, NxM configurations of
MODE will be run.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>quilt = false;
</pre></div>
</div>
<p><strong>fcst, obs</strong></p>
<p>The object definition settings for MODE are contained within the “fcst” and
“obs” entries:</p>
<ul>
<li><p>The “censor_thresh” and “censor_val” entries are described above.
The entries replace the previously supported “raw_thresh” entry.</p></li>
<li><p>The “conv_radius” entry specifies the convolution radius in grid
squares. The larger the convolution radius, the smoother the objects.
Multiple convolution radii may be specified as an array. For example:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>conv_radius = [ 5, 10, 15 ];
</pre></div>
</div>
</li>
<li><p>The “conv_thresh” entry specifies the convolution threshold used to
define MODE objects. The lower the threshold, the larger the objects.
Multiple convolution thresholds may be specified as an array. For example:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>conv_thresh = [ &gt;=5.0, &gt;=10.0, &gt;=15.0 ];
</pre></div>
</div>
</li>
<li><p>The “vld_thresh” entry is described above.</p></li>
<li><p>The “filter_attr_name” and “filter_attr_thresh” entries are arrays of
the same length which specify object filtering criteria. By default, no
object filtering criteria is defined.</p>
<p>The “filter_attr_name” entry is an array of strings specifying the MODE
output header column names for the object attributes of interest, such
as “AREA”, “LENGTH”, “WIDTH”, and “INTENSITY_50”. In addition,
“ASPECT_RATIO” specifies the aspect ratio (width/length),
“INTENSITY_101” specifies the  mean intensity value, and “INTENSITY_102”
specifies the sum of the intensity values.</p>
<p>The “filter_attr_thresh” entry is an array of thresholds for the
object attributes. Any simple objects not meeting all of these
filtering criteria are discarded.</p>
<p>Note that the “area_thresh” and “inten_perc_thresh” entries form
earlier versions of MODE are replaced by these options and are now
deprecated.</p>
</li>
<li><p>The “merge_thresh” entry specifies a lower convolution threshold used
when the double-threshold merging method is applied. The number of
merge thresholds must match the number of convolution thresholds.
Multiple merge thresholds may be specified as an array. For example:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>merge_thresh = [ &gt;=1.0, &gt;=2.0, &gt;=3.0 ];
</pre></div>
</div>
</li>
<li><p>The “merge_flag” entry specifies the merging methods to be applied:</p>
<blockquote>
<div><ul class="simple">
<li><p>“NONE” for no merging</p></li>
<li><p>“THRESH” for the double-threshold merging method. Merge objects
that would be part of the same object at the lower threshold.</p></li>
<li><p>“ENGINE” for the fuzzy logic approach comparing the field to itself</p></li>
<li><p>“BOTH” for both the double-threshold and engine merging methods</p></li>
</ul>
</div></blockquote>
</li>
</ul>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>fcst = {
   field = {
      name  = &quot;APCP&quot;;
      level = &quot;A03&quot;;
   }

   censor_thresh      = [];
   censor_val         = [];
   conv_radius        = 60.0/grid_res; in grid squares
   conv_thresh        = &gt;=5.0;
   vld_thresh         = 0.5;
   filter_attr_name   = [];
   filter_attr_thresh = [];
   merge_thresh       = &gt;=1.25;
   merge_flag         = THRESH;
}
</pre></div>
</div>
<p><strong>grid_res</strong></p>
<p>The “grid_res” entry is the nominal spacing for each grid square in
kilometers. The variable is not used directly in the code, but subsequent
variables in the configuration files are defined in terms of it. Therefore,
setting the appropriately will help ensure that appropriate default values
are used for these variables.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>grid_res = 4;
</pre></div>
</div>
<p><strong>match_flag</strong></p>
<p>The “match_flag” entry specifies the matching method to be applied:</p>
<ul class="simple">
<li><p>“NONE” for no matching between forecast and observation objects</p></li>
<li><p>“MERGE_BOTH” for matching allowing additional merging in both fields.
If two objects in one field match the same object in the other field,
those two objects are merged.</p></li>
<li><p>“MERGE_FCST” for matching allowing only additional forecast merging</p></li>
<li><p>“NO_MERGE” for matching with no additional merging in either field</p></li>
</ul>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>match_flag = MERGE_BOTH;
</pre></div>
</div>
<p><strong>max_centroid_dist</strong></p>
<p>The “max_centroid_dist” entry specifies the maximum allowable distance in
grid squares between the centroids of objects for them to be compared.
Setting this to a reasonable value speeds up the runtime enabling MODE to
skip unreasonable object comparisons.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>max_centroid_dist = 800.0/grid_res;
</pre></div>
</div>
<p><strong>weight</strong></p>
<p>The weight variables control how much weight is assigned to each pairwise
attribute when computing a total interest value for object pairs. The weights
need not sum to any particular value but must be non-negative. When the
total interest value is computed, the weighted sum is normalized by the
sum of the weights listed.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>weight = {
   centroid_dist    = 2.0;
   boundary_dist    = 4.0;
   convex_hull_dist = 0.0;
   angle_diff       = 1.0;
   area_ratio       = 1.0;
   int_area_ratio   = 2.0;
   complexity_ratio = 0.0;
   inten_perc_ratio = 0.0;
   inten_perc_value = 50;
}
</pre></div>
</div>
<p><strong>interest_function</strong></p>
<p>The set of interest function variables listed define which values are of
interest for each pairwise attribute measured. The interest functions may be
defined as a piecewise linear function or as an algebraic expression. A
piecewise linear function is defined by specifying the corner points of its
graph. An algebraic function may be defined in terms of several built-in
mathematical functions.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>interest_function = {

   centroid_dist = (
      (            0.0, 1.0 )
      (  60.0/grid_res, 1.0 )
      ( 600.0/grid_res, 0.0 )
   );

   boundary_dist = (
      (            0.0, 1.0 )
      ( 400.0/grid_res, 0.0 )
   );

   convex_hull_dist = (
      (            0.0, 1.0 )
      ( 400.0/grid_res, 0.0 )
   );

   angle_diff = (
      (  0.0, 1.0 )
      ( 30.0, 1.0 )
      ( 90.0, 0.0 )
   );

   corner   = 0.8;
   ratio_if = (
      (    0.0, 0.0 )
      ( corner, 1.0 )
      (    1.0, 1.0 )
   );

   area_ratio = ratio_if;

   int_area_ratio = (
      ( 0.00, 0.00 )
      ( 0.10, 0.50 )
      ( 0.25, 1.00 )
      ( 1.00, 1.00 )
   );

   complexity_ratio = ratio_if;

   inten_perc_ratio = ratio_if;
}
</pre></div>
</div>
<p><strong>total_interest_thresh</strong></p>
<p>The total_interest_thresh variable should be set between 0 and 1. This
threshold is applied to the total interest values computed for each pair of
objects and is used in determining matches.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>total_interest_thresh = 0.7;
</pre></div>
</div>
<p><strong>print_interest_thresh</strong></p>
<p>The print_interest_thresh variable determines which pairs of object
attributes will be written to the output object attribute ASCII file. The
user may choose to set the print_interest_thresh to the same value as the
total_interest_thresh, meaning that only object pairs that actually match are
written to the output file. When set to zero, all object pair attributes will
be written as long as the distance between the object centroids is less than
the max_centroid_dist variable.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>print_interest_thresh = 0.0;
</pre></div>
</div>
<p><strong>plot_valid_flag</strong></p>
<p>When applied, the plot_valid_flag variable indicates that only the region
containing valid data after masking is applied should be plotted. TRUE
indicates the entire domain should be plotted; FALSE indicates only the
region containing valid data after masking should be plotted.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>plot_valid_flag = FALSE;
</pre></div>
</div>
<p><strong>plot_gcarc_flag</strong></p>
<p>When applied, the plot_gcarc_flag variable indicates that the edges of
polylines should be plotted using great circle arcs as opposed to straight
lines in the grid.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>plot_gcarc_flag = FALSE;
</pre></div>
</div>
<p><strong>ct_stats_flag</strong></p>
<p>The ct_stats_flag can be set to TRUE or FALSE to produce additional output,
in the form of contingency table counts and statistics.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>ct_stats_flag = TRUE;
</pre></div>
</div>
<p><strong>shift_right</strong></p>
<p>When MODE is run on global grids, this parameter specifies how many grid
squares to shift the grid to the right. MODE does not currently connect
objects from one side of a global grid to the other, potentially causing
objects straddling that longitude to be cut in half. Shifting the grid by
some amount enables the user to control where that longitude cut line occurs.
This option provides a very specialized case of automated regridding. The
much more flexible “regrid” option may be used instead.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>shift_right = 0;
</pre></div>
</div>
</div>
<div class="section" id="pb2ncconfig-default">
<h4><span class="section-number">26.1.2.4. </span>PB2NCConfig_default<a class="headerlink" href="#pb2ncconfig-default" title="Permalink to this headline">¶</a></h4>
<p>The PB2NC tool filters out observations from PREPBUFR or BUFR files using the
following criteria:</p>
<ol class="arabic">
<li><p>by message type: supply a list of PREPBUFR message types to retain</p></li>
<li><p>by station id: supply a list of observation stations to retain</p></li>
<li><p>by valid time: supply the beginning and ending time offset values
in the obs_window entry described above.</p></li>
<li><p>by location: use the “mask” entry described below to supply either
an NCEP masking grid, a masking lat/lon polygon or a file to a
mask lat/lon polygon</p></li>
<li><p>by elevation: supply min/max elevation values</p></li>
<li><p>by report type: supply a list of report types to retain using
pb_report_type and in_report_type entries described below</p></li>
<li><p>by instrument type: supply a list of instrument type to
retain</p></li>
<li><p>by vertical level: supply beg/end vertical levels using the
level_range entry described below</p></li>
<li><p>by variable type: supply a list of observation variable types to
retain using the obs_bufr_var entry described below</p></li>
<li><p>by quality mark: supply a quality mark threshold</p></li>
<li><p>Flag to retain values for all quality marks, or just the first
quality mark (highest): use the event_stack_flag described below</p></li>
<li><p>by data level category: supply a list of category types to
retain.</p>
<p>0 - Surface level (mass reports only)</p>
<p>1 - Mandatory level (upper-air profile reports)</p>
<p>2 - Significant temperature level (upper-air profile reports)</p>
<p>2 - Significant temperature and winds-by-pressure level
(future combined mass and wind upper-air reports)</p>
<p>3 - Winds-by-pressure level (upper-air profile reports)</p>
<p>4 - Winds-by-height level (upper-air profile reports)</p>
<p>5 - Tropopause level (upper-air profile reports)</p>
<p>6 - Reports on a single level
(e.g., aircraft, satellite-wind, surface wind,
precipitable water retrievals, etc.)</p>
<p>7 - Auxiliary levels generated via interpolation from spanning levels
(upper-air profile reports)</p>
</li>
</ol>
<p><strong>message_type</strong></p>
<p>In the PB2NC tool, the “message_type” entry is an array of message types
to be retained. An empty list indicates that all should be retained.</p>
<div class="line-block">
<div class="line">List of valid message types:</div>
<div class="line">ADPUPA AIRCAR AIRCFT ADPSFC ERS1DA GOESND GPSIPW</div>
<div class="line">MSONET PROFLR QKSWND RASSDA SATEMP SATWND SFCBOG</div>
<div class="line">SFCSHP SPSSMI SYNDAT VADWND</div>
</div>
<p>For example:</p>
<div class="line-block">
<div class="line">message_type[] = [ “ADPUPA”, “AIRCAR” ];</div>
<div class="line"><br /></div>
</div>
<p><a class="reference external" href="http://www.emc.ncep.noaa.gov/mmb/data_processing/prepbufr.doc/table_1.htm">Current Table A Entries in PREPBUFR mnemonic table</a></p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>message_type = [];
</pre></div>
</div>
<p><strong>message_type_group_map</strong></p>
<p>Mapping of message type group name to comma-separated list of values.
The default setting defines ANYAIR, ANYSFC, and ONLYSF as groups.
Derive PRMSL only for SURFACE message types.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>message_type_group_map = [
   { key = &quot;SURFACE&quot;; val = &quot;ADPSFC,SFCSHP,MSONET&quot;;               },
   { key = &quot;ANYAIR&quot;;  val = &quot;AIRCAR,AIRCFT&quot;;                      },
   { key = &quot;ANYSFC&quot;;  val = &quot;ADPSFC,SFCSHP,ADPUPA,PROFLR,MSONET&quot;; },
   { key = &quot;ONLYSF&quot;;  val = &quot;ADPSFC,SFCSHP&quot;;                      }
];
</pre></div>
</div>
<p><strong>station_id</strong></p>
<p>The “station_id” entry is an array of station ids to be retained or
the filename which contains station ids. An array of station ids
contains a comma-separated list. An empty list indicates that all
stations should be retained.</p>
<p>For example:  station_id = [ “KDEN” ];</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>station_id = [];
</pre></div>
</div>
<p><strong>elevation_range</strong></p>
<p>The “elevation_range” entry is a dictionary which contains “beg” and “end”
entries specifying the range of observing locations elevations to be
retained.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>elevation_range = {
   beg =  -1000;
   end = 100000;
}
</pre></div>
</div>
<p><strong>pb_report_type</strong></p>
<p>The “pb_report_type” entry is an array of PREPBUFR report types to be
retained. The numeric “pb_report_type” entry allows for further
stratification within message types. An empty list indicates that all should
be retained.</p>
<p>See: <a class="reference external" href="http://www.emc.ncep.noaa.gov/mmb/data_processing/prepbufr.doc/table_4.htm">Code table for PREPBUFR report types used by Regional NAM GSI analyses</a></p>
<p>For example:</p>
<div class="line-block">
<div class="line">Report Type 120 is for message type ADPUPA but is only RAWINSONDE</div>
<div class="line">Report Type 132 is for message type ADPUPA but is only FLIGHT-LEVEL RECON</div>
<div class="line">and PROFILE DROPSONDE</div>
<div class="line"><br /></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>pb_report_type  = [];
</pre></div>
</div>
<p><strong>in_report_type</strong></p>
<p>The “in_report_type” entry is an array of input report type values to be
retained. The numeric “in_report_type” entry provides additional
stratification of observations. An empty list indicates that all should
be retained.</p>
<p>See: <a class="reference external" href="http://www.emc.ncep.noaa.gov/mmb/data_processing/prepbufr.doc/table_6.htm">Code table for input report types</a></p>
<p>For example:</p>
<div class="line-block">
<div class="line">Input Report Type 11 Fixed land RAOB and PIBAL by block and station number</div>
<div class="line">Input Report Type 12 Fixed land RAOB and PIBAL by call letters</div>
<div class="line"><br /></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>in_report_type = [];
</pre></div>
</div>
<p><strong>instrument_type</strong></p>
<p>The “instrument_type” entry is an array of instrument types to be retained.
An empty list indicates that all should be retained.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>instrument_type = [];
</pre></div>
</div>
<p><strong>level_range</strong></p>
<p>The “level_range” entry is a dictionary which contains “beg” and “end”
entries specifying the range of vertical levels (1 to 255) to be retained.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>level_range = {
   beg = 1;
   end = 255;
}
</pre></div>
</div>
<p><strong>level_category</strong></p>
<p>The “level_category” entry is an array of integers specifying which level
categories should be retained:</p>
<div class="line-block">
<div class="line">0 = Surface level (mass reports only)</div>
</div>
<div class="line-block">
<div class="line">1 = Mandatory level (upper-air profile reports)</div>
</div>
<div class="line-block">
<div class="line">2 = Significant temperature level (upper-air profile reports)</div>
</div>
<div class="line-block">
<div class="line">2 = Significant temperature and winds-by-pressure level (future combined mass</div>
<div class="line-block">
<div class="line">and wind upper-air reports)</div>
</div>
</div>
<div class="line-block">
<div class="line">3 = Winds-by-pressure level (upper-air profile reports)</div>
</div>
<div class="line-block">
<div class="line">4 = Winds-by-height level (upper-air profile reports)</div>
</div>
<div class="line-block">
<div class="line">5 = Tropopause level (upper-air profile reports)</div>
</div>
<div class="line-block">
<div class="line">6 = Reports on a single level  (For example: aircraft, satellite-wind,</div>
<div class="line-block">
<div class="line">surface wind, precipitable water retrievals, etc.)</div>
</div>
</div>
<div class="line-block">
<div class="line">7 = Auxiliary levels generated via interpolation from spanning levels</div>
<div class="line-block">
<div class="line">(upper-air profile reports)</div>
</div>
</div>
<div class="line-block">
<div class="line"><br /></div>
</div>
<p>An empty list indicates that all should be retained.</p>
<p>See: <a class="reference external" href="http://www.emc.ncep.noaa.gov/mmb/data_processing/prepbufr.doc/table_1.htm">Current Table A Entries in PREPBUFR mnemonic table</a></p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>level_category = [];
</pre></div>
</div>
<p><strong>obs_bufr_var</strong></p>
<p>The “obs_bufr_var” entry is an array of strings containing BUFR variable
names to be retained or derived. This replaces the “obs_grib_code” setting
from earlier versions of MET. Run PB2NC on your data with the “-index”
command line option to see the list of available observation variables.</p>
<div class="line-block">
<div class="line">Observation variables that can be derived begin with “D_”:</div>
<div class="line-block">
<div class="line">D_DPT   for Dew point Temperature in K</div>
<div class="line">D_WDIR  for Wind Direction</div>
<div class="line">D_WIND  for Wind Speed in m/s</div>
<div class="line">D_RH    for Relative Humidity in %</div>
<div class="line">D_MIXR  for Humidity Mixing Ratio in kg/kg</div>
<div class="line">D_PRMSL for Pressure Reduced to Mean Sea Level in Pa</div>
<div class="line"><br /></div>
</div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>obs_bufr_var = [ &quot;QOB&quot;, &quot;TOB&quot;, &quot;ZOB&quot;, &quot;UOB&quot;, &quot;VOB&quot; ];
</pre></div>
</div>
<p><strong>obs_bufr_map</strong></p>
<p>Mapping of input BUFR variable names to output variables names.
The default PREPBUFR map, obs_prepbufr_map, is appended to this map.
Users may choose to rename BUFR variables to match the naming convention
of the forecast the observation is used to verify.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>obs_bufr_map = [];
</pre></div>
</div>
<p><strong>obs_prefbufr_map</strong></p>
<p>Default mapping for PREPBUFR. Replace input BUFR variable names with GRIB
abbreviations in the output. This default map is appended to obs_bufr_map.
This should not typically be overridden. This default mapping provides
backward-compatibility for earlier versions of MET which wrote GRIB
abbreviations to the output.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>obs_prefbufr_map = [
   { key = &quot;POB&quot;;     val = &quot;PRES&quot;;  },
   { key = &quot;QOB&quot;;     val = &quot;SPFH&quot;;  },
   { key = &quot;TOB&quot;;     val = &quot;TMP&quot;;   },
   { key = &quot;ZOB&quot;;     val = &quot;HGT&quot;;   },
   { key = &quot;UOB&quot;;     val = &quot;UGRD&quot;;  },
   { key = &quot;VOB&quot;;     val = &quot;VGRD&quot;;  },
   { key = &quot;D_DPT&quot;;   val = &quot;DPT&quot;;   },
   { key = &quot;D_WDIR&quot;;  val = &quot;WDIR&quot;;  },
   { key = &quot;D_WIND&quot;;  val = &quot;WIND&quot;;  },
   { key = &quot;D_RH&quot;;    val = &quot;RH&quot;;    },
   { key = &quot;D_MIXR&quot;;  val = &quot;MIXR&quot;;  },
   { key = &quot;D_PRMSL&quot;; val = &quot;PRMSL&quot;; }
];
</pre></div>
</div>
<p><strong>quality_mark_thresh</strong></p>
<p>The “quality_mark_thresh” entry specifies the maximum quality mark value
to be retained. Observations with a quality mark LESS THAN OR EQUAL TO
this threshold will be retained, while observations with a quality mark
GREATER THAN this threshold will be discarded.</p>
<p>See <a class="reference external" href="http://www.emc.ncep.noaa.gov/mmb/data_processing/prepbufr.doc/table_7.htm">Code table for observation quality markers</a></p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>quality_mark_thresh = 2;
</pre></div>
</div>
<p><strong>event_stack_flag</strong></p>
<p>The “event_stack_flag” entry is set to “TOP” or “BOTTOM” to
specify whether observations should be drawn from the top of the event
stack (most quality controlled) or the bottom of the event stack (most raw).</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>event_stack_flag = TOP;
</pre></div>
</div>
</div>
<div class="section" id="seriesanalysisconfig-default">
<h4><span class="section-number">26.1.2.5. </span>SeriesAnalysisConfig_default<a class="headerlink" href="#seriesanalysisconfig-default" title="Permalink to this headline">¶</a></h4>
<p><strong>block_size</strong></p>
<p>Computation may be memory intensive, especially for large grids.
The “block_size” entry sets the number of grid points to be processed
concurrently (i.e. in one pass through a time series). Smaller values
require less memory but increase the number of passes through the data.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>block_size = 1024;
</pre></div>
</div>
<p><strong>vld_thresh</strong></p>
<p>Ratio of valid matched pairs to total length of series for a grid
point. If valid threshold is exceeded at that grid point the statistics
are computed and stored. If not, a bad data flag is stored. The default
setting requires all data in the series to be valid.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>vld_thresh = 1.0;
</pre></div>
</div>
<p><strong>output_stats</strong></p>
<p>Statistical output types need to be specified explicitly. Refer to User’s
Guide for available output types. To keep output file size reasonable,
it is recommended to process a few output types at a time, especially if the
grid is large.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>output_stats = {
   fho    = [];
   ctc    = [];
   cts    = [];
   mctc   = [];
   mcts   = [];
   cnt    = [ &quot;RMSE&quot;, &quot;FBAR&quot;, &quot;OBAR&quot; ];
   sl1l2  = [];
   pct    = [];
   pstd   = [];
   pjc    = [];
   prc    = [];
}
</pre></div>
</div>
</div>
<div class="section" id="statanalysisconfig-default">
<h4><span class="section-number">26.1.2.6. </span>STATAnalysisConfig_default<a class="headerlink" href="#statanalysisconfig-default" title="Permalink to this headline">¶</a></h4>
<p><strong>jobs</strong></p>
<p>The “jobs” entry is an array of STAT-Analysis jobs to be performed.
Each element in the array contains the specifications for a single analysis
job to be performed. The format for an analysis job is as follows:</p>
<div class="line-block">
<div class="line">-job job_name</div>
<div class="line">OPTIONAL ARGS</div>
<div class="line"><br /></div>
</div>
<p>Where “job_name” is set to one of the following:</p>
<ul>
<li><p>“filter”</p>
<p>To filter out the STAT or TCMPR lines matching the job filtering
criteria specified below and using the optional arguments below.
The output STAT lines are written to the file specified using the
“-dump_row” argument.
Required Args: -dump_row</p>
</li>
</ul>
<div class="line-block">
<div class="line"><br /></div>
</div>
<ul>
<li><p>“summary”</p>
<p>To compute summary information for a set of statistics.
The summary output includes the mean, standard deviation,
percentiles (0th, 10th, 25th, 50th, 75th, 90th, and 100th), range,
and inter-quartile range. Also included are columns summarizing the
computation of WMO mean values. Both unweighted and weighted mean
values are reported, and they are computed using three types of
logic:</p>
<ul class="simple">
<li><p>simple arithmetic mean (default)</p></li>
<li><p>square root of the mean of the statistic squared
(applied to columns listed in “wmo_sqrt_stats”)</p></li>
<li><p>apply fisher transform
(applied to columns listed in “wmo_fisher_stats”)</p></li>
</ul>
</li>
</ul>
<div class="line-block">
<div class="line"><br /></div>
</div>
<blockquote>
<div><p>The columns of data to be summarized are specified in one of two
ways:</p>
<ul class="simple">
<li><p>Specify the -line_type option once and specify one or more column names.</p></li>
<li><p>Format the -column option as LINE_TYPE:COLUMN.</p></li>
</ul>
</div></blockquote>
<div class="line-block">
<div class="line"><br /></div>
</div>
<blockquote>
<div><p>Use the -derive job command option to automatically derive
statistics on the fly from input contingency tables and partial
sums.</p>
<p>Use the -column_union TRUE/FALSE job command option to compute
summary statistics across the union of input columns rather than
processing them separately.</p>
<p>For TCStat, the “-column” argument may be set to:</p>
<blockquote>
<div><ul class="simple">
<li><p>“TRACK” for track, along-track, and cross-track errors.</p></li>
<li><p>“WIND” for all wind radius errors.</p></li>
<li><p>“TI” for track and maximum wind intensity errors.</p></li>
<li><p>“AC” for along-track and cross-track errors.</p></li>
<li><p>“XY” for x-track and y-track errors.</p></li>
<li><p>“col” for a specific column name.</p></li>
<li><p>“col1-col2” for a difference of two columns.</p></li>
<li><p>“ABS(col or col1-col2)” for the absolute value.</p></li>
</ul>
</div></blockquote>
<p>Required Args: -line_type, -column</p>
<p>Optional Args:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>-by column_name to specify case information
-out_alpha to override default alpha value of 0.05
-derive to derive statistics on the fly
-column_union to summarize multiple columns
</pre></div>
</div>
</div></blockquote>
<ul>
<li><p>“aggregate”</p>
<p>To aggregate the STAT data for the STAT line type specified using
the “-line_type” argument. The output of the job will be in the
same format as the input line type specified. The following line
types may be aggregated:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>-line_type FHO, CTC, MCTC,
           SL1L2, SAL1L2, VL1L2, VAL1L2,
           PCT, NBRCNT, NBRCTC, GRAD,
           ISC, ECNT, RPS, RHIST, PHIST, RELP, SSVAR
</pre></div>
</div>
<p>Required Args: -line_type</p>
</li>
</ul>
<div class="line-block">
<div class="line"><br /></div>
</div>
<ul>
<li><p>“aggregate_stat”</p>
<p>To aggregate the STAT data for the STAT line type specified using
the “-line_type” argument. The output of the job will be the line
type specified using the “-out_line_type” argument. The valid
combinations of “-line_type” and “-out_line_type” are listed below.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>-line_type FHO, CTC,      -out_line_type CTS, ECLV
-line_type MCTC           -out_line_type MCTS
-line_type SL1L2, SAL1L2, -out_line_type CNT
-line_type VL1L2          -out_line_type VCNT
-line_type VL1L2, VAL1L2, -out_line_type WDIR (wind direction)
-line_type PCT,           -out_line_type PSTD, PJC, PRC, ECLV
-line_type NBRCTC,        -out_line_type NBRCTS
-line_type ORANK,         -out_line_type ECNT, RPS, RHIST, PHIST,
                                         RELP, SSVAR
-line_type MPR,           -out_line_type FHO, CTC, CTS,
                                         MCTC, MCTS, CNT,
                                         SL1L2, SAL1L2,
                                         VL1L2, VCNT,
                                         PCT, PSTD, PJC, PRC, ECLV,
                                         WDIR (wind direction)
</pre></div>
</div>
<p>Required Args: -line_type, -out_line_type</p>
<p>Additional Required Args for -line_type MPR:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>-out_thresh or -out_fcst_thresh and -out_obs_thresh
 When -out_line_type FHO, CTC, CTS, MCTC, MCTS,
                     PCT, PSTD, PJC, PRC
</pre></div>
</div>
<p>Additional Optional Args for -line_type MPR:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>-mask_grid, -mask_poly, -mask_sid
-out_thresh or -out_fcst_thresh and -out_obs_thresh
-out_cnt_logic
-out_wind_thresh or -out_fcst_wind_thresh and
-out_obs_wind_thresh
-out_wind_logic
When -out_line_type WDIR
</pre></div>
</div>
<p>Additional Optional Arg for:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>-line_type ORANK -out_line_type PHIST, SSVAR ...
-out_bin_size
</pre></div>
</div>
<p>Additional Optional Args for:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>-out_line_type ECLV ...
-out_eclv_points
</pre></div>
</div>
</li>
<li><p>“ss_index”</p>
<p>The skill score index job can be configured to compute a weighted
average of skill scores derived from a configurable set of
variables, levels, lead times, and statistics. The skill score
index is computed using two models, a forecast model and a
reference model. For each statistic in the index, a skill score
is computed as:</p>
<p>SS = 1 - (S[model]*S[model])/(S[reference]*S[reference])</p>
<p>Where S is the statistic.</p>
<p>Next, a weighted average is computed over all the skill scores.</p>
<p>Lastly, an index value is computed as:</p>
<p>Index = sqrt(1/(1-SS[avg]))</p>
<p>Where SS[avg] is the weighted average of skill scores.</p>
<p>Required Args:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Exactly 2 entries for -model, the forecast model and reference
For each term of the index:
-fcst_var, -fcst_lev, -fcst_lead, -line_type, -column, -weight
Where -line_type is CNT or CTS and -column is the statistic.
Optionally, specify other filters for each term, -fcst_thresh.
</pre></div>
</div>
</li>
<li><p>“go_index”</p>
<p>The GO Index is a special case of the skill score index consisting
of a predefined set of variables, levels, lead times, statistics,
and weights.</p>
<p>For lead times of 12, 24, 36, and 48 hours, it contains RMSE for:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>- Wind Speed at the surface(b), 850(a), 400(a), 250(a) mb
- Dew point Temperature at the surface(b), 850(b), 700(b), 400(b) mB
- Temperature at the surface(b), 400(a) mB
- Height at 400(a) mB
- Sea Level Pressure(b)
Where (a) means weights of 4, 3, 2, 1 for the lead times, and
      (b) means weights of 8, 6, 4, 2 for the lead times.
</pre></div>
</div>
<p>Required Args: None</p>
</li>
</ul>
<div class="line-block">
<div class="line"><br /></div>
</div>
<ul>
<li><p>“ramp”</p>
<p>The ramp job operates on a time-series of forecast and observed
values and is analogous to the RIRW (Rapid Intensification and
Weakening) job supported by the tc_stat tool. The amount of change
from one time to the next is computed for forecast and observed
values. Those changes are thresholded to define events which are
used to populate a 2x2 contingency table.</p>
<p>Required Args:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>-ramp_thresh (-ramp_thresh_fcst or -ramp_thresh_obs)
   For DYDT, threshold for the amount of change required to
   define an event.
   For SWING, threshold the slope.
-swing_width val
   Required for the swinging door algorithm width.
</pre></div>
</div>
<p>Optional Args:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>-ramp_type str
   Overrides the default ramp definition algorithm to be used.
   May be set to DYDT (default) or SWING for the swinging door
   algorithm.
-line_type str
   Overrides the default input line type, MPR.
-out_line_type str
   Overrides the default output line types of CTC and CTS.
   Set to CTC,CTS,MPR for all possible output types.
-column fcst_column,obs_column
   Overrides the default forecast and observation columns
   to be used, FCST and OBS.
-ramp_time HH[MMSS] (-ramp_time_fcst or -ramp_time_obs)
   Overrides the default ramp time interval, 1 hour.
-ramp_exact true/false (-ramp_exact_fcst or -ramp_exact_obs)
   Defines ramps using an exact change (true, default) or maximum
   change in the time window (false).
-ramp_window width in HH[MMSS] format
-ramp_window beg end in HH[MMSS] format
   Defines a search time window when attempting to convert misses
   to hits and false alarms to correct negatives. Use 1 argument
   to define a symmetric time window or 2 for an asymmetric
   window. Default window is 0 0, requiring an exact match.
</pre></div>
</div>
<p>Job command FILTERING options to further refine the STAT data:</p>
<p>Each optional argument may be used in the job specification multiple
times unless otherwise indicated. When multiple optional arguments of
the same type are indicated, the analysis will be performed over their
union:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>&quot;-model            name&quot;
&quot;-fcst_lead        HHMMSS&quot;
&quot;-obs_lead         HHMMSS&quot;
&quot;-fcst_valid_beg   YYYYMMDD[_HH[MMSS]]&quot; (use once)
&quot;-fcst_valid_end   YYYYMMDD[_HH[MMSS]]&quot; (use once)
&quot;-obs_valid_beg    YYYYMMDD[_HH[MMSS]]&quot; (use once)
&quot;-obs_valid_end    YYYYMMDD[_HH[MMSS]]&quot; (use once)
&quot;-fcst_init_beg    YYYYMMDD[_HH[MMSS]]&quot; (use once)
&quot;-fcst_init_end    YYYYMMDD[_HH[MMSS]]&quot; (use once)
&quot;-obs_init_beg     YYYYMMDD[_HH[MMSS]]&quot; (use once)
&quot;-obs_init_end     YYYYMMDD[_HH[MMSS]]&quot; (use once)
&quot;-fcst_init_hour   HH[MMSS]&quot;
&quot;-obs_init_hour    HH[MMSS]&quot;
&quot;-fcst_valid_hour&quot; HH[MMSS]
&quot;-obs_valid_hour&quot;  HH[MMSS]
&quot;-fcst_var         name&quot;
&quot;-obs_var          name&quot;
&quot;-fcst_lev         name&quot;
&quot;-obs_lev          name&quot;
&quot;-obtype           name&quot;
&quot;-vx_mask          name&quot;
&quot;-interp_mthd      name&quot;
&quot;-interp_pnts      n&quot;
&quot;-fcst_thresh      t&quot;
&quot;-obs_thresh       t&quot;
&quot;-cov_thresh       t&quot;
&quot;-thresh_logic     UNION, or, ||
                   INTERSECTION, and, &amp;&amp;
                   SYMDIFF, symdiff, *
&quot;-alpha            a&quot;
&quot;-line_type        type&quot;
&quot;-column           name&quot;
&quot;-weight           value&quot;
</pre></div>
</div>
<p>Job command FILTERING options that may be used only when -line_type
has been listed once. These options take two arguments: the name of the
data column to be used and the min, max, or exact value for that column.
If multiple column eq/min/max/str options are listed, the job will be
performed on their intersection:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>&quot;-column_min    col_name value&quot;     e.g. -column_min BASER 0.02
&quot;-column_max    col_name value&quot;
&quot;-column_eq     col_name value&quot;
&quot;-column_thresh col_name threshold&quot; e.g. -column_thresh FCST &#39;&gt;273&#39;
&quot;-column_str    col_name string&quot; separate multiple filtering strings
                                 with commas
</pre></div>
</div>
<p>Job command options to DEFINE the analysis job. Unless otherwise noted,
these options may only be used ONCE per analysis job:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>&quot;-dump_row        path&quot;
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>&quot;-mask_grid       name&quot;
&quot;-mask_poly       file&quot;
&quot;-mask_sid        file|list&quot; see description of &quot;sid&quot; entry above
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>&quot;-out_line_type   name&quot;
&quot;-out_thresh      value&quot; sets both -out_fcst_thresh and -out_obs_thresh
&quot;-out_fcst_thresh value&quot; multiple for multi-category contingency tables
                         and probabilistic forecasts
&quot;-out_obs_thresh  value&quot; multiple for multi-category contingency tables
&quot;-out_cnt_logic   value&quot;
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>&quot;-out_wind_thresh      value&quot;
&quot;-out_fcst_wind_thresh value&quot;
&quot;-out_obs_wind_thresh  value&quot;
&quot;-out_wind_logic       value&quot;
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>&quot;-out_bin_size    value&quot;
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>&quot;-out_eclv_points value&quot; see description of &quot;eclv_points&quot; config file
                         entry
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>&quot;-out_alpha       value&quot;
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>&quot;-boot_interval   value&quot;
&quot;-boot_rep_prop   value&quot;
&quot;-n_boot_rep      value&quot;
&quot;-boot_rng        value&quot;
&quot;-boot_seed       value&quot;
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>&quot;-rank_corr_flag  value&quot;
&quot;-vif_flag        value&quot;
</pre></div>
</div>
<p>For aggregate and aggregate_stat job types:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>&quot;-out_stat        path&quot;   to write a .stat output file for the job
                          including the .stat header columns. Multiple
                          values for each header column are written as
                          a comma-separated list.
&quot;-set_hdr col_name value&quot; may be used multiple times to explicity
                          specify what should be written to the header
                          columns of the output .stat file.
</pre></div>
</div>
<p>When using the “-by” job command option, you may reference those columns
in the “-set_hdr” job command options. For example, when computing statistics
separately for each station, write the station ID string to the VX_MASK column
of the output .stat output file:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>-job aggregate_stat -line_type MPR -out_line_type CNT \
-by OBS_SID -set_hdr VX_MASK OBS_SID -stat_out out.stat
When using mulitple &quot;-by&quot; options, use &quot;CASE&quot; to reference the full string:
-by FCST_VAR,OBS_SID -set_hdr DESC CASE -stat_out out.stat
</pre></div>
</div>
</li>
</ul>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>jobs = [
   &quot;-job filter         -line_type SL1L2 -vx_mask DTC165 \
    -dump_row  job_filter_SL1L2.stat&quot;,
   &quot;-job summary        -line_type CNT   -alpha 0.050 -fcst_var TMP \
    -dump_row job_summary_ME.stat -column ME&quot;,
   &quot;-job aggregate      -line_type SL1L2 -vx_mask DTC165 -vx_mask DTC166 \
    -fcst_var TMP -dump_row job_aggregate_SL1L2_dump.stat  \
    -out_stat job_aggregate_SL1L2_out.stat \
    -set_hdr VX_MASK CONUS&quot;,
   &quot;-job aggregate_stat -line_type SL1L2 -out_line_type CNT -vx_mask DTC165  \
    -vx_mask DTC166 -fcst_var TMP \
    -dump_row  job_aggregate_stat_SL1L2_CNT_in.stat&quot;,
   &quot;-job aggregate_stat -line_type MPR   -out_line_type CNT -vx_mask DTC165 \
    -vx_mask DTC166 -fcat_var TMP -dump_row job_aggregate_stat_MPR_CNT_in.stat&quot;,
   &quot;-job aggregate      -line_type CTC   -fcst_thresh &lt;300.000 -vx_mask DTC165 \
    -vx_mask DTC166 -fcst_var TMP -dump_row job_aggregate_CTC_in.stat&quot;,
   &quot;-job aggregate_stat -line_type CTC   -out_line_type CTS \
    -fcst_thresh &lt;300.000 -vx_mask DTC165 -vx_mask DTC166 -fcst_var TMP \
    -dump_row job_aggregate_stat_CTC_CTS_in.stat&quot;,
   &quot;-job aggregate      -line_type MCTC  -column_eq N_CAT 4 -vx_mask DTC165 \
    -vx_mask DTC166 -fcst_var APCP_24 -dump_row job_aggregate_MCTC_in.stat&quot;,
   &quot;-job aggregate_stat -line_type MCTC  -out_line_type MCTS \
    -column_eq N_CAT 4 -vx_mask DTC165 -vx_mask DTC166 -fcst_var APCP_24 \
    -dump_row job_aggregate_stat_MCTC_MCTS_in.stat&quot;,
   &quot;-job aggregate      -line_type PCT   -vx_mask DTC165 -vx_mask DTC166 \
    -dump_row job_aggregate_PCT_in.stat&quot;,
   &quot;-job aggregate_stat -line_type PCT   -out_line_type PSTD -vx_mask DTC165 \
    -vx_mask DTC166 -dump_row job_aggregate_stat_PCT_PSTD_in.stat&quot;,
   &quot;-job aggregate      -line_type ISC   -fcst_thresh &gt;0.000 -vx_mask TILE_TOT \
    -fcst_var APCP_12 -dump_row job_aggregate_ISC_in.stat&quot;,
   &quot;-job aggregate      -line_type RHIST -obtype MC_PCP -vx_mask HUC4_1605 \
    -vx_mask HUC4_1803 -dump_row job_aggregate_RHIST_in.stat&quot;,
   &quot;-job aggregate      -line_type SSVAR -obtype MC_PCP -vx_mask HUC4_1605 \
    -vx_mask HUC4_1803 -dump_row job_aggregate_SSVAR_in.stat&quot;,
   &quot;-job aggregate_stat -line_type ORANK -out_line_type RHIST -obtype ADPSFC \
    -vx_mask HUC4_1605 -vx_mask HUC4_1803 \
    -dump_row job_aggregate_stat_ORANK_RHIST_in.stat&quot;
];
</pre></div>
</div>
<p>List of statistics by the logic that should be applied when computing their
WMO mean value in the summary job. Each entry is a line type followed by the
statistic name. Statistics using the default arithemtic mean method do not
need to be listed.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>wmo_sqrt_stats   = [];
wmo_fisher_stats = [];
</pre></div>
</div>
<p>The “vif_flag” entry is a boolean to indicate whether a variance inflation
factor should be computed when aggregating a time series of contingency
table counts or partial sums. The VIF is used to adjust the normal
confidence intervals computed for the aggregated statistics.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>vif_flag = FALSE;
</pre></div>
</div>
</div>
<div class="section" id="waveletstatconfig-default">
<h4><span class="section-number">26.1.2.7. </span>WaveletStatConfig_default<a class="headerlink" href="#waveletstatconfig-default" title="Permalink to this headline">¶</a></h4>
<p><strong>grid_decomp_flag</strong></p>
<p>The “grid_decomp_flag” entry specifies how the grid should be decomposed in
Wavelet-Stat into dyadic (2^n x 2^n) tiles:</p>
<ul class="simple">
<li><p>“AUTO” to tile the input data using tiles of dimension n by n where n
is the largest integer power of 2 less than the smallest dimension of
the input data. Center as many tiles as possible with no overlap.</p></li>
<li><p>“TILE” to use the tile definition specified below.</p></li>
<li><p>“PAD” to pad the input data out to the nearest integer power of 2.</p></li>
</ul>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>grid_decomp_flag = AUTO;
</pre></div>
</div>
<p><strong>tile</strong></p>
<p>The “tile” entry is a dictionary that specifies how tiles should be defined
in Wavelet-Stat when the “grid_decomp_flag” is set to “TILE”:</p>
<ul class="simple">
<li><p>The “width” entry specifies the dimension for all tiles and must be
an integer power of 2.</p></li>
<li><p>The “location” entry is an array of dictionaries where each element
consists of an “x_ll” and “y_ll” entry specifying the lower-left (x,y)
coordinates of the tile.</p></li>
</ul>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>tile = {
   width = 0;
   location = [
      {
         x_ll = 0;
         y_ll = 0;
      }
   ];
}
</pre></div>
</div>
<p><strong>wavelet</strong></p>
<p>The “wavelet” entry is a dictionary in Wavelet-Stat that specifies how the
wavelet decomposition should be performed:</p>
<ul class="simple">
<li><p>The “type” entry specifies which wavelet should be used.</p></li>
<li><p>The “member” entry specifies the wavelet shape.
See: <a class="reference external" href="https://www.gnu.org/software/gsl/doc/html/dwt.html#initialization">Discrete Wavelet Transforms (DWT) initialization</a></p></li>
<li><p>Valid combinations of the two are listed below:</p>
<ul>
<li><p>“HAAR” for Haar wavelet (member = 2)</p></li>
<li><p>“HAAR_CNTR” for Centered-Haar wavelet (member = 2)</p></li>
<li><p>“DAUB” for Daubechies wavelet (member = 4, 6, 8, 10, 12, 14, 16,
18, 20)</p></li>
<li><p>“DAUB_CNTR” for Centered-Daubechies wavelet (member = 4, 6, 8, 10,
12, 14, 16, 18, 20)</p></li>
<li><p>“BSPLINE” for Bspline wavelet (member = 103, 105, 202, 204, 206,
208, 301, 303, 305, 307, 309)</p></li>
<li><p>“BSPLINE_CNTR” for Centered-Bspline wavelet (member = 103, 105, 202,
204, 206, 208, 301, 303, 305, 307, 309)</p></li>
</ul>
</li>
</ul>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>wavelet = {
   type   = HAAR;
   member = 2;
}
</pre></div>
</div>
<p><strong>obs_raw_plot, wvlt_plot, object_plot</strong></p>
<p>The “obs_raw_plot”, “wvlt_plot”, and “object_plot” entries are dictionaries
similar to the “fcst_raw_plot” described in the “Settings common to multiple
tools” section.</p>
</div>
<div class="section" id="wwmcaregridconfig-default">
<h4><span class="section-number">26.1.2.8. </span>WWMCARegridConfig_default<a class="headerlink" href="#wwmcaregridconfig-default" title="Permalink to this headline">¶</a></h4>
<p><strong>to_grid</strong></p>
<p>Specify the grid to which the data should be interpolated in one of the
following ways:</p>
<ul class="simple">
<li><p>Name (“GNNN” where NNN indicates the three digit NCEP grid number)</p></li>
<li><p>lambert Nx Ny lat_ll lon_ll lon_orient D_km R_km standard_parallel_1
[standard_parallel_2] N|S</p></li>
<li><p>stereo Nx Ny lat_ll lon_ll lon_orient D_km R_km lat_scale N|S</p></li>
<li><p>latlon Nx Ny lat_ll lon_ll delta_lat delta_lon</p></li>
<li><p>mercator Nx Ny lat_ll lon_ll lat_ur lon_ur</p></li>
<li><p>gaussian lon_zero Nx Ny</p></li>
</ul>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>to_grid = &quot;lambert 614 428 12.190 -133.459 -95.0 12.19058 6367.47 25.0 N&quot;;
</pre></div>
</div>
<p><strong>NetCDF output information</strong></p>
<p>Supply the NetCDF output information.  For example:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>variable_name = &quot;Cloud_Pct&quot;;
units         = &quot;percent&quot;;
long_name     = &quot;cloud cover percent&quot;;
level         = &quot;SFC&quot;;
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>variable_name = &quot;&quot;;
units         = &quot;&quot;;
long_name     = &quot;&quot;;
level         = &quot;&quot;;
</pre></div>
</div>
<p><strong>max_minutes (pixel age)</strong></p>
<p>Maximum pixel age in minutes</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>max_minutes = 120;
</pre></div>
</div>
<p><strong>swap_endian</strong></p>
<p>The WWMCA pixel age data is stored in binary data files in 4-byte blocks.
The swap_endian option indicates whether the endian-ness of the data should
be swapped after reading.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>swap_endian = TRUE;
</pre></div>
</div>
<p><strong>write_pixel_age</strong></p>
<p>By default, wwmca_regrid writes the cloud percent data specified on the
command line to the output file. This option writes the pixel age data,
in minutes, to the output file instead.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>write_pixel_age = FALSE;
</pre></div>
</div>
</div>
</div>
</div>
</div>


           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="README_TC.html" class="btn btn-neutral float-right" title="27. README_TC Configuration File Overview" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="plotting.html" class="btn btn-neutral" title="25. Plotting and Graphics Support" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, UCAR/NCAR, NOAA, CSU/CIRA, and CU/CIRES.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
     
<script>var version_json_loc = "../../versions.json";</script>


</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script src="../_static/pop_ver.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>